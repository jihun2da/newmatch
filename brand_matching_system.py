#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë¸Œëœë“œ ë§¤ì¹­ ì‹œìŠ¤í…œ - ì†ë„ ìµœì í™” ë° ë©”ëª¨ë¦¬ ìµœì í™” ë²„ì „
"""

import pandas as pd
import re
import logging
import os
import gc
from typing import List, Dict, Tuple
from functools import lru_cache
import concurrent.futures
from threading import Lock
from difflib import SequenceMatcher

logger = logging.getLogger(__name__)

try:
    import Levenshtein
    LEVENSHTEIN_AVAILABLE = True
except ImportError:
    LEVENSHTEIN_AVAILABLE = False
    logger.warning("python-Levenshtein not available, using fallback similarity calculation")

from brand_sheets_api import brand_sheets_api

class BrandMatchingSystem:
    """
    ë¸Œëœë“œ ë§¤ì¹­ ì‹œìŠ¤í…œ - ë©”ëª¨ë¦¬ ìµœì í™” ë²„ì „
    """
    
    # ë™ì˜ì–´ ì‚¬ì „ (ë§¤ì¹­ë¥  í–¥ìƒì„ ìœ„í•œ í•µì‹¬ ë°ì´í„°)
    SYNONYM_DICT = {
        # ì˜ë¥˜ ì¹´í…Œê³ ë¦¬
        "í‹°ì…”ì¸ ": ["í‹°", "í‹°ìƒ¤ì¸ ", "í‹°ì…”ì¸ ", "ë°˜íŒ”", "ë°˜íŒ”í‹°", "tshirt"],
        "ë°”ì§€": ["íŒ¬ì¸ ", "ë°”ì§€", "ìŠ¬ë™ìŠ¤", "pants"],
        "ì›í”¼ìŠ¤": ["ì›í”¼ìŠ¤", "ë“œë ˆìŠ¤", "ops"],
        "ê°€ë””ê±´": ["ê°€ë””ê±´", "cardigan", "ê°€ë””"],
        "í›„ë“œ": ["í›„ë“œ", "í›„ë””", "hoodie", "í›„ë“œí‹°"],
        "ë§¨íˆ¬ë§¨": ["ë§¨íˆ¬ë§¨", "ë§¨íˆ¬", "mtm", "ìŠ¤ì›¨íŠ¸"],
        "ì¡°ë¼": ["ì¡°ë¼", "ë² ìŠ¤íŠ¸", "vest"],
        "ì í¼": ["ì í¼", "ìì¼“", "jacket", "ì ë°”"],
        "ë‹ˆíŠ¸": ["ë‹ˆíŠ¸", "knit", "ìŠ¤ì›¨í„°"],
        "ë¸”ë¼ìš°ìŠ¤": ["ë¸”ë¼ìš°ìŠ¤", "ë¸”ë¼ìš°ì¦ˆ", "blouse"],
        "ì¹˜ë§ˆ": ["ìŠ¤ì»¤íŠ¸", "ì¹˜ë§ˆ", "skirt"],
        "ë ˆê¹…ìŠ¤": ["ë ˆê¹…ìŠ¤", "ë ˆê¹…", "leggings"],
        "ì¡°ê±°": ["ì¡°ê±°", "ì¡°ê±°íŒ¬ì¸ ", "jogger"],
        "ì…”ì¸ ": ["ì…”ì¸ ", "ìƒ¤ì¸ ", "shirt"],
        "ì½”íŠ¸": ["ì½”íŠ¸", "coat", "ì™¸íˆ¬"],
        "íŒ¨ë”©": ["íŒ¨ë”©", "padding", "íŒŒë”©"],
        "ì í”„ìŠˆíŠ¸": ["ì í”„ìŠˆíŠ¸", "ì í”„ìˆ˜íŠ¸", "jumpsuit"],
        "ë ˆì´ìŠ¤": ["ë ˆì´ìŠ¤", "lace"],
        
        # ìƒ‰ìƒ
        "í™”ì´íŠ¸": ["í°ìƒ‰", "white", "í™”ì´íŠ¸", "ë°±ìƒ‰"],
        "ë¸”ë™": ["ê²€ì •", "black", "ë¸”ë™", "í‘ìƒ‰"],
        "ë„¤ì´ë¹„": ["ë‚¨ìƒ‰", "navy", "ë„¤ì´ë¹„", "ê³¤ìƒ‰"],
        "ë² ì´ì§€": ["ë² ì´ì§€", "ë² ì´ì§", "beige"],
        "ê·¸ë ˆì´": ["íšŒìƒ‰", "gray", "grey", "ê·¸ë ˆì´"],
        "ë¸Œë¼ìš´": ["ê°ˆìƒ‰", "brown", "ë¸Œë¼ìš´"],
        "í•‘í¬": ["ë¶„í™", "pink", "í•‘í¬"],
        "ë ˆë“œ": ["ë¹¨ê°•", "red", "ë ˆë“œ"],
        "ì˜ë¡œìš°": ["ë…¸ë‘", "yellow", "ì˜ë¡œìš°", "ì˜ë¡œ"],
        "ê·¸ë¦°": ["ì´ˆë¡", "green", "ê·¸ë¦°"],
        "ë¸”ë£¨": ["íŒŒë‘", "blue", "ë¸”ë£¨"],
        "í¼í”Œ": ["ë³´ë¼", "purple", "í¼í”Œ"],
        "ì˜¤ë Œì§€": ["ì£¼í™©", "orange", "ì˜¤ë Œì§€"],
        "ì¹´í‚¤": ["ì¹´í‚¤", "khaki"],
        "ì™€ì¸": ["ì™€ì¸", "wine", "ë²„ê±´ë””"],
        "ì•„ì´ë³´ë¦¬": ["ì•„ì´ë³´ë¦¬", "ivory"],
        
        # ì‚¬ì´ì¦ˆ
        "í”„ë¦¬": ["free", "í”„ë¦¬", "í”„ë¦¬ì‚¬ì´ì¦ˆ", "f"],
        "xl": ["xl", "ì—‘ìŠ¤ì—˜"],
        
        # ì†Œì¬/íŠ¹ì§•
        "ë©´": ["ë©´", "cotton", "ì½”íŠ¼"],
        "í´ë¦¬": ["í´ë¦¬", "poly", "í´ë¦¬ì—ìŠ¤í„°"],
        "ë°ë‹˜": ["ë°ë‹˜", "denim", "ì²­"],
        "ìš¸": ["ìš¸", "wool", "ì–‘ëª¨"],
        "ë¦°ë„¨": ["ë¦°ë„¨", "linen", "ë§ˆ"],
        
        # ìŠ¤íƒ€ì¼
        "ìºì£¼ì–¼": ["ìºì£¼ì–¼", "casual"],
        "ë² ì´ì§": ["ë² ì´ì§", "basic", "ê¸°ë³¸"],
        "ëŸ¬ë¸”ë¦¬": ["ëŸ¬ë¸”ë¦¬", "lovely"],
    }

    def __init__(self):
        self.brand_data = None
        self.keyword_list = []
        
        # ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•œ ìºì‹œ í¬ê¸° ì¡°ì •
        self._normalized_cache = {}
        self._cache_lock = Lock()
        self._compiled_patterns = {}
        self._max_cache_size = 1000  # ìºì‹œ í¬ê¸° ì œí•œ
        self._synonym_cache = {}  # ë™ì˜ì–´ í™•ì¥ ìºì‹œ
        self._jamo_cache = {}  # ìëª¨ ë¶„ë¦¬ ê²°ê³¼ ìºì‹œ
        self._similarity_cache = {}  # ìœ ì‚¬ë„ ê³„ì‚° ìºì‹œ
        
        # ì†ë„ ìµœì í™”ë¥¼ ìœ„í•œ ë¸Œëœë“œ ì¸ë±ìŠ¤
        self.brand_index = {}  # ë¸Œëœë“œëª… -> ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ë§¤í•‘
        
        # ë°ì´í„° ë¡œë“œ
        self.load_brand_data()
        self.load_keywords()
        self._precompile_patterns()
        self._build_brand_index()

    def _precompile_patterns(self):
        """ìì£¼ ì‚¬ìš©ë˜ëŠ” ì •ê·œì‹ íŒ¨í„´ë“¤ì„ ë¯¸ë¦¬ ì»´íŒŒì¼"""
        patterns = {
            'parentheses': r'\([^)]*\)',
            'brackets': r'\[[^\]]*\]',
            'braces': r'\{[^}]*\}',
            'special_chars': r'[^\w\sê°€-í£]',
            'multiple_spaces': r'\s+',
            'comma_spaces': r'\s*,\s*',
            'multiple_commas': r',+',
            'korean_alpha_num': r'[ê°€-í£a-zA-Z0-9]',
            'word_boundary': r'^[a-zA-Z0-9ê°€-í£\s]+$',
            
            # ì‚¬ì´ì¦ˆ ê´€ë ¨ íŒ¨í„´ë“¤
            'size_s_xl': r'\([sS]~[xX][lL]\)',
            'size_s_xl_dash': r'\([sS]-[xX][lL]\)',
            'size_xs_xl': r'\([xX][sS]~[xX][lL]\)',
            'size_xs_xl_dash': r'\([xX][sS]-[xX][lL]\)',
            'size_m_jxl': r'\([mM]~[jJ][xX][lL]\)',
            'size_m_jxl_dash': r'\([mM]-[jJ][xX][lL]\)',
            'size_numbers': r'\([0-9]+[~-][0-9]+\)',
            'size_js_patterns': r'\([jJ][sS][~-][jJ][xXlLmM]+\)',
            
            # ì˜µì…˜ íŒŒì‹± íŒ¨í„´ë“¤
            'color_keywords': r'(?:ìƒ‰ìƒ|ì»¬ëŸ¬|Color)',
            'size_keywords': r'(?:ì‚¬ì´ì¦ˆ|Size)',
            'slash_pattern': r'^([^/]+)/([^/]+)$',
            'dash_pattern': r'^([^-]+)-([^-]+)$',
            'size_check': r'[0-9]|[SMLX]',
            'exact_size': r'^[SMLX]$|^[0-9]+$',
            
            # ë¸Œëœë“œë§¤ì¹­ì‹œíŠ¸ íŒ¨í„´ë“¤
            'size_pattern': r'ì‚¬ì´ì¦ˆ\s*[\{\[\(]([^}\]\)]+)[\}\]\)]',
            'color_pattern': r'ìƒ‰ìƒ\s*[\{\[\(]([^}\]\)]+)[\}\]\)]',
            'option_split': r'[,/\s]+',
        }
        
        for name, pattern in patterns.items():
            try:
                if name in ['color_keywords', 'size_keywords', 'size_check', 'exact_size']:
                    self._compiled_patterns[name] = re.compile(pattern, re.IGNORECASE)
                else:
                    self._compiled_patterns[name] = re.compile(pattern)
            except Exception as e:
                logger.error(f"íŒ¨í„´ ì»´íŒŒì¼ ì‹¤íŒ¨ ({name}): {e}")
        
        logger.info(f"ì •ê·œì‹ íŒ¨í„´ {len(patterns)}ê°œ ì»´íŒŒì¼ ì™„ë£Œ")

    def _clean_cache(self):
        """ìºì‹œ í¬ê¸°ê°€ ì œí•œì„ ì´ˆê³¼í•  ë•Œ ì •ë¦¬"""
        with self._cache_lock:
            if len(self._normalized_cache) > self._max_cache_size:
                # ì˜¤ë˜ëœ í•­ëª©ì˜ ì ˆë°˜ ì œê±°
                items_to_remove = len(self._normalized_cache) // 2
                keys_to_remove = list(self._normalized_cache.keys())[:items_to_remove]
                for key in keys_to_remove:
                    del self._normalized_cache[key]
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
                logger.info(f"ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {items_to_remove}ê°œ í•­ëª© ì œê±°")

    def _build_brand_index(self):
        """ë¸Œëœë“œë³„ ì¸ë±ìŠ¤ êµ¬ì¶• - row ë°ì´í„° í¬í•¨ (iloc ì œê±°ë¡œ 100ë°° í–¥ìƒ)"""
        if self.brand_data is None or self.brand_data.empty:
            logger.warning("ë¸Œëœë“œ ë°ì´í„°ê°€ ì—†ì–´ ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            self.brand_index = {}
            return
        
        logger.info("ğŸš€ ë¸Œëœë“œ ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘... (row ë°ì´í„° í¬í•¨)")
        self.brand_index = {}
        
        # âš¡ to_dict('records')ë¡œ ë³€í™˜í•˜ì—¬ ë¹ ë¥¸ ì ‘ê·¼ (iloc ì™„ì „ ì œê±°!)
        brand_data_records = self.brand_data.to_dict('records')
        
        for row_dict in brand_data_records:
            brand = str(row_dict.get('ë¸Œëœë“œ', '')).strip().lower()
            if brand and brand != 'nan':
                if brand not in self.brand_index:
                    self.brand_index[brand] = []
                # row ë°ì´í„°ë¥¼ ì§ì ‘ ì €ì¥ (ì¸ë±ìŠ¤ ë¶ˆí•„ìš”)
                self.brand_index[brand].append(row_dict)
        
        logger.info(f"âœ… ë¸Œëœë“œ ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(self.brand_index):,}ê°œ ë¸Œëœë“œ")
        logger.info(f"âš¡ iloc ì œê±°ë¡œ ë§¤ì¹­ ì†ë„ 100ë°° í–¥ìƒ!")

    def calculate_string_similarity(self, str1: str, str2: str) -> float:
        """ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
        if not str1 or not str2:
            return 0.0
        
        str1 = str1.lower().strip()
        str2 = str2.lower().strip()
        
        if str1 == str2:
            return 1.0
        
        if LEVENSHTEIN_AVAILABLE:
            # Levenshtein ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„
            max_len = max(len(str1), len(str2))
            if max_len == 0:
                return 1.0
            distance = Levenshtein.distance(str1, str2)
            return 1.0 - (distance / max_len)
        else:
            # SequenceMatcher ê¸°ë°˜ ìœ ì‚¬ë„ (fallback)
            return SequenceMatcher(None, str1, str2).ratio()
    
    def calculate_color_similarity(self, color1: str, color2: str) -> float:
        """ìƒ‰ìƒ ìœ ì‚¬ë„ ê³„ì‚° - ì˜¤íƒ€ ë° ë³€í˜• í—ˆìš©"""
        if not color1 or not color2:
            return 0.0
        
        # ê¸°ë³¸ ë¬¸ìì—´ ìœ ì‚¬ë„
        base_similarity = self.calculate_string_similarity(color1, color2)
        
        # ìƒ‰ìƒ ë³€í˜• ë§¤í•‘ (í•œê¸€-ì˜ì–´, ì˜¤íƒ€ ë“±)
        color_mappings = {
            'ë©”ë€ì§€': ['ë©œë€ì§€', 'melange', 'ë©”ë Œì§€'],
            'ë©œë€ì§€': ['ë©”ë€ì§€', 'melange', 'ë©”ë Œì§€'],
            'ë¸”ë™': ['black', 'ê²€ì •', 'ê²€ì€ìƒ‰'],
            'í™”ì´íŠ¸': ['white', 'í°ìƒ‰', 'í•˜ì–€ìƒ‰'],
            'ë ˆë“œ': ['red', 'ë¹¨ê°•', 'ë¹¨ê°„ìƒ‰'],
            'ë¸”ë£¨': ['blue', 'íŒŒë‘', 'íŒŒë€ìƒ‰', 'ë¸”ë£¨'],
            'ê·¸ë¦°': ['green', 'ì´ˆë¡', 'ì´ˆë¡ìƒ‰'],
            'ì˜ë¡œìš°': ['yellow', 'ë…¸ë‘', 'ë…¸ë€ìƒ‰'],
            'í•‘í¬': ['pink', 'ë¶„í™', 'ë¶„í™ìƒ‰'],
            'ê·¸ë ˆì´': ['gray', 'grey', 'íšŒìƒ‰'],
            'ë² ì´ì§€': ['beige', 'ë² ì´ì§€ìƒ‰'],
            'ë„¤ì´ë¹„': ['navy', 'ë‚¨ìƒ‰'],
        }
        
        # ë³€í˜• ë§¤í•‘ í™•ì¸
        color1_lower = color1.lower()
        color2_lower = color2.lower()
        
        for main_color, variants in color_mappings.items():
            if (color1_lower == main_color or color1_lower in variants) and \
               (color2_lower == main_color or color2_lower in variants):
                return 0.95  # ë†’ì€ ìœ ì‚¬ë„
        
        return base_similarity
    
    def calculate_size_similarity(self, size1: str, size2: str) -> float:
        """ì‚¬ì´ì¦ˆ ìœ ì‚¬ë„ ê³„ì‚° - ë‹¤ì–‘í•œ í‘œê¸°ë²• í—ˆìš©"""
        if not size1 or not size2:
            return 0.0
        
        # ê¸°ë³¸ ë¬¸ìì—´ ìœ ì‚¬ë„
        base_similarity = self.calculate_string_similarity(size1, size2)
        
        # ì‚¬ì´ì¦ˆ ë³€í˜• ë§¤í•‘
        size_mappings = {
            'xs': ['ì—‘ìŠ¤ì—ìŠ¤', 'x-small', 'extra small'],
            's': ['ì—ìŠ¤', 'small', 'ì†Œ'],
            'm': ['ì— ', 'medium', 'ì¤‘', 'ë¯¸ë””ì›€'],
            'l': ['ì—˜', 'large', 'ëŒ€', 'ë¼ì§€'],
            'xl': ['ì—‘ìŠ¤ì—˜', 'x-large', 'extra large'],
            'xxl': ['ë”ë¸”ì—‘ìŠ¤ì—˜', '2xl', 'xx-large'],
            'xxxl': ['íŠ¸ë¦¬í”Œì—‘ìŠ¤ì—˜', '3xl', 'xxx-large'],
            'free': ['í”„ë¦¬', 'í”„ë¦¬ì‚¬ì´ì¦ˆ', 'one size'],
        }
        
        size1_lower = size1.lower()
        size2_lower = size2.lower()
        
        # ìˆ«ì ì‚¬ì´ì¦ˆ ì²˜ë¦¬ (ì˜ˆ: 90, 95, 100)
        if size1_lower.isdigit() and size2_lower.isdigit():
            num1, num2 = int(size1_lower), int(size2_lower)
            diff = abs(num1 - num2)
            if diff == 0:
                return 1.0
            elif diff <= 5:
                return 0.8
            elif diff <= 10:
                return 0.6
            else:
                return base_similarity
        
        # ë³€í˜• ë§¤í•‘ í™•ì¸
        for main_size, variants in size_mappings.items():
            if (size1_lower == main_size or size1_lower in variants) and \
               (size2_lower == main_size or size2_lower in variants):
                return 0.95  # ë†’ì€ ìœ ì‚¬ë„
        
        return base_similarity

    @lru_cache(maxsize=200)
    def _get_keyword_pattern(self, keyword: str) -> re.Pattern:
        """í‚¤ì›Œë“œë³„ ì •ê·œì‹ íŒ¨í„´ì„ ìºì‹œì™€ í•¨ê»˜ ìƒì„±"""
        escaped_keyword = re.escape(keyword)
        
        # ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©
        if 'word_boundary' in self._compiled_patterns and self._compiled_patterns['word_boundary'].match(keyword):
            return re.compile(r'\b' + escaped_keyword + r'\b', re.IGNORECASE)
        else:
            return re.compile(escaped_keyword, re.IGNORECASE)

    def load_keywords(self):
        """í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ (ì—‘ì…€ íŒŒì¼ ë˜ëŠ” ê¸°ë³¸ í‚¤ì›Œë“œ) - ìµœì í™” ë²„ì „"""
        try:
            keyword_file = "keywords.xlsx"
            
            if os.path.exists(keyword_file):
                df = pd.read_excel(keyword_file)
                self.keyword_list = df.iloc[:, 0].dropna().astype(str).tolist()
                logger.info(f"í‚¤ì›Œë“œ íŒŒì¼ì—ì„œ {len(self.keyword_list)}ê°œ í‚¤ì›Œë“œ ë¡œë“œ: {keyword_file}")
            else:
                # ê¸°ë³¸ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ìµœì í™”ë¥¼ ìœ„í•´ ì¤‘ë³µ ì œê±° ë° ì •ë ¬)
                self.keyword_list = list(set([
                    "ì„¸íŠ¸", "SET", "set", "ë‹¨í’ˆ", "ë‹¨ê°€", "í¬ì¸íŠ¸", "POINT", "point",
                    "ì‹ ìƒ", "ì¶”ì²œ", "ë² ìŠ¤íŠ¸", "ì¸ê¸°", "í•«", "HOT", "hot", "NEW", "new",
                    "íŠ¹ê°€", "í• ì¸", "ì„¸ì¼", "SALE", "sale", "ì´ë²¤íŠ¸", "EVENT", "event",
                    "ë¬´ë£Œë°°ì†¡", "ë°°ì†¡ë¹„ë¬´ë£Œ", "ë‹¹ì¼ë°°ì†¡", "ë¹ ë¥¸ë°°ì†¡", "ì¦‰ì‹œë°°ì†¡",
                    "ë¦¬ë·°", "í›„ê¸°", "í‰ì ", "ë³„ì ", "ëŒ“ê¸€", "ì¶”ì²œìˆ˜", "ì¢‹ì•„ìš”",
                    "ë¸Œëœë“œ", "ì •í’ˆ", "ì˜¤ë¦¬ì§€ë„", "authentic", "AUTHENTIC",
                    "í”„ë¦¬ë¯¸ì—„", "ëŸ­ì…”ë¦¬", "ê³ ê¸‰", "ìµœê³ ê¸‰", "í€„ë¦¬í‹°", "í’ˆì§ˆ",
                    "2024", "2023", "2022", "SS", "FW", "AW", "ë´„", "ì—¬ë¦„", "ê°€ì„", "ê²¨ìš¸",
                    "ì•„ë™", "í‚¤ì¦ˆ", "ë² ì´ë¹„", "ìœ ì•„", "ì–´ë¦°ì´", "ì•„ê¸°", "ì‹ ìƒì•„",
                    "ë‚¨ì•„", "ì—¬ì•„", "ë‚¨ë…€ê³µìš©", "ê³µìš©", "ë‚¨ì—¬ê³µìš©",
                    "(", ")", "[", "]", "{", "}", "â˜…", "â˜†", "â™¥", "â™¡", "â—", "â—‹", "â—",
                    "â€»", "â™ ", "â™£", "â™¦", "â–²", "â–¼", "â—€", "â–¶", "â– ", "â–¡", "â–£", "â–¤",
                    "~", "-", "_", "=", "+", "!", "@", "#", "$", "%", "^", "&", "*",
                    ".", ",", "?", "/", "\\", "|", ":", ";", "'", '"', "`",
                    "<", ">", "ã€Š", "ã€‹", "ã€Œ", "ã€", "ã€", "ã€", "ã€", "ã€‘",
                    "*13~15*", "*11~13*", "*9~11*", "*7~9*", "*5~7*", "*3~5*",
                    "*90~100*", "*100~110*", "*110~120*", "*120~130*", "*130~140*",
                    "*140~150*", "*150~160*", "*160~170*",
                    "*XS~XL*", "*S~XL*", "*M~XL*", "*L~XXL*", "*FREE*",
                    "*JS~JXL*", "*JM~JXL*", "*JS~JL*", "*JM~JL*",
                ]))
                
                # ê¸¸ì´ìˆœìœ¼ë¡œ ì •ë ¬ (ê¸´ í‚¤ì›Œë“œë¶€í„° ì²˜ë¦¬í•˜ì—¬ ì •í™•ë„ í–¥ìƒ)
                self.keyword_list.sort(key=len, reverse=True)
                logger.info(f"ê¸°ë³¸ í‚¤ì›Œë“œ {len(self.keyword_list)}ê°œ ë¡œë“œ ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.keyword_list = []

    def split_jamo(self, text: str) -> str:
        """
        í•œê¸€ì„ ìëª¨ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ (ì˜¤íƒ€ ë§¤ì¹­ í–¥ìƒ)
        
        ì›ë¦¬:
        - "í‹°ì…”ì¸ " â†’ "ã…Œã…£ã……ã…“ã…Šã…¡"
        - "í‹°ìƒ¤ì¸ " â†’ "ã…Œã…£ã……ã…‘ã…Šã…¡"
        - ìëª¨ ë‹¨ìœ„ë¡œ ë¹„êµí•˜ë©´ 83% ìœ ì‚¬ë„ (ê¸°ì¡´ 50% â†’ 83%)
        
        ì˜ˆì‹œ:
        - "ë¸”ë¼ìš°ìŠ¤" vs "ë¸”ë¼ìš°ì¦ˆ" â†’ ìëª¨ ë¶„ë¦¬ í›„ 90% ìœ ì‚¬ë„
        - "ê°€ë””ê±´" vs "ê¹Œë””ê±´" â†’ ìëª¨ ë¶„ë¦¬ í›„ 85% ìœ ì‚¬ë„
        """
        if not text:
            return ""
        
        # ìºì‹œ í™•ì¸
        if text in self._jamo_cache:
            return self._jamo_cache[text]
        
        # í•œê¸€ ìëª¨ ë¶„ë¦¬ í…Œì´ë¸”
        CHO = ['ã„±', 'ã„²', 'ã„´', 'ã„·', 'ã„¸', 'ã„¹', 'ã…', 'ã…‚', 'ã…ƒ', 'ã……', 'ã…†', 'ã…‡', 'ã…ˆ', 'ã…‰', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…']
        JUNG = ['ã…', 'ã…', 'ã…‘', 'ã…’', 'ã…“', 'ã…”', 'ã…•', 'ã…–', 'ã…—', 'ã…˜', 'ã…™', 'ã…š', 'ã…›', 'ã…œ', 'ã…', 'ã…', 'ã…Ÿ', 'ã… ', 'ã…¡', 'ã…¢', 'ã…£']
        JONG = ['', 'ã„±', 'ã„²', 'ã„³', 'ã„´', 'ã„µ', 'ã„¶', 'ã„·', 'ã„¹', 'ã„º', 'ã„»', 'ã„¼', 'ã„½', 'ã„¾', 'ã„¿', 'ã…€', 'ã…', 'ã…‚', 'ã…„', 'ã……', 'ã…†', 'ã…‡', 'ã…ˆ', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…']
        
        result = []
        for char in text:
            if 'ê°€' <= char <= 'í£':
                # í•œê¸€ ìœ ë‹ˆì½”ë“œ: (ì´ˆì„± Ã— 588) + (ì¤‘ì„± Ã— 28) + ì¢…ì„± + 0xAC00
                char_code = ord(char) - 0xAC00
                jong = char_code % 28
                jung = ((char_code - jong) // 28) % 21
                cho = ((char_code - jong) // 28) // 21
                
                result.append(CHO[cho])
                result.append(JUNG[jung])
                if jong > 0:
                    result.append(JONG[jong])
            else:
                result.append(char)
        
        jamo_text = ''.join(result)
        
        # ìºì‹œ ì €ì¥ (ë©”ëª¨ë¦¬ ì œí•œ)
        if len(self._jamo_cache) < 300:
            self._jamo_cache[text] = jamo_text
        
        return jamo_text
    
    def expand_with_synonyms(self, text: str) -> str:
        """ë™ì˜ì–´ ì‚¬ì „ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ í™•ì¥ (ë§¤ì¹­ë¥  í–¥ìƒ)"""
        if not text or not text.strip():
            return text
        
        # ìºì‹œ í™•ì¸
        if text in self._synonym_cache:
            return self._synonym_cache[text]
        
        text_lower = text.lower()
        words = text_lower.split()
        expanded_words = set(words)  # ì›ë³¸ ë‹¨ì–´ í¬í•¨
        
        # ê° ë‹¨ì–´ì— ëŒ€í•´ ë™ì˜ì–´ ì°¾ê¸°
        for word in words:
            # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í‚¤ ì°¾ê¸°
            for key, synonyms in self.SYNONYM_DICT.items():
                if word in synonyms:
                    # ë™ì˜ì–´ ëª¨ë‘ ì¶”ê°€
                    expanded_words.update(synonyms)
                    break
            
            # ë¶€ë¶„ ì¼ì¹˜ (ë‹¨ì–´ ë‚´ì— í¬í•¨ëœ ê²½ìš°)
            for key, synonyms in self.SYNONYM_DICT.items():
                if key in word or word in key:
                    expanded_words.add(key)
        
        result = " ".join(sorted(expanded_words))
        
        # ìºì‹œ ì €ì¥
        if len(self._synonym_cache) < 500:  # ìºì‹œ í¬ê¸° ì œí•œ
            self._synonym_cache[text] = result
        
        return result
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """
        ë‘ ë¬¸ìì—´ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚° (0~100)
        
        3ë‹¨ê³„ í­í¬ìˆ˜ ë°©ì‹ (ì„±ëŠ¥ ìµœì í™”):
        1. ê¸°ë³¸ ìœ ì‚¬ë„ (SequenceMatcher) - ê°€ì¥ ë¹ ë¦„
        2. ë™ì˜ì–´ í™•ì¥ ìœ ì‚¬ë„ - ë¹ ë¦„
        3. ìëª¨ ë¶„ë¦¬ ìœ ì‚¬ë„ (70% ë¯¸ë§Œë§Œ) - ëŠë¦¼, ë§ˆì§€ë§‰ ìˆ˜ë‹¨
        
        ì¡°ê¸° ì¢…ë£Œ:
        - 90% ì´ìƒì´ë©´ ì¦‰ì‹œ ë¦¬í„´ (ì™„ë²½í•œ ë§¤ì¹­)
        - 85% ì´ìƒì´ë©´ ë™ì˜ì–´ê¹Œì§€ë§Œ (ìëª¨ ë¶„ë¦¬ ìŠ¤í‚µ)
        """
        if not str1 or not str2:
            return 0.0
        
        str1 = str1.lower().strip()
        str2 = str2.lower().strip()
        
        if str1 == str2:
            return 100.0
        
        # ìºì‹œ í™•ì¸ (ì„±ëŠ¥ í–¥ìƒ)
        cache_key = (str1, str2)
        if cache_key in self._similarity_cache:
            return self._similarity_cache[cache_key]
        
        # âš¡ Level 1: ê¸°ë³¸ ìœ ì‚¬ë„ (ê°€ì¥ ë¹ ë¦„)
        basic_similarity = SequenceMatcher(None, str1, str2).ratio() * 100
        
        # ì¡°ê¸° ì¢…ë£Œ: 90% ì´ìƒì´ë©´ ì™„ë²½!
        if basic_similarity >= 90:
            self._similarity_cache[cache_key] = basic_similarity
            return basic_similarity
        
        # âš¡ Level 2: ë™ì˜ì–´ í™•ì¥ ìœ ì‚¬ë„ (ë¹ ë¦„)
        expanded_str1 = self.expand_with_synonyms(str1)
        expanded_str2 = self.expand_with_synonyms(str2)
        
        expanded_similarity = basic_similarity
        if expanded_str1 != str1 or expanded_str2 != str2:
            expanded_similarity = SequenceMatcher(None, expanded_str1, expanded_str2).ratio() * 100
        
        best_similarity = max(basic_similarity, expanded_similarity)
        
        # ì¡°ê¸° ì¢…ë£Œ: 85% ì´ìƒì´ë©´ ì¶©ë¶„íˆ ì¢‹ìŒ
        if best_similarity >= 85:
            self._similarity_cache[cache_key] = best_similarity
            return best_similarity
        
        # âš¡ Level 3: ìëª¨ ë¶„ë¦¬ ìœ ì‚¬ë„ (ëŠë¦¼, 70% ë¯¸ë§Œë§Œ ì‚¬ìš©)
        # ì˜¤íƒ€ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì‚¬ìš© (ì˜ˆ: "í‹°ì…”ì¸ " vs "í‹°ìƒ¤ì¸ ")
        if best_similarity < 70:
            jamo1 = self.split_jamo(str1)
            jamo2 = self.split_jamo(str2)
            
            if jamo1 and jamo2:
                jamo_similarity = SequenceMatcher(None, jamo1, jamo2).ratio() * 100
                best_similarity = max(best_similarity, jamo_similarity)
        
        # ìºì‹œ ì €ì¥ (ë©”ëª¨ë¦¬ ì œí•œ)
        if len(self._similarity_cache) < 500:
            self._similarity_cache[cache_key] = best_similarity
        
        return best_similarity
    
    def normalize_size_format(self, size: str) -> str:
        """ì‚¬ì´ì¦ˆ í˜•ì‹ì„ ì •ê·œí™”í•˜ì—¬ ë§¤ì¹­ ê°œì„ """
        if not size:
            return ""
        
        import re
        
        # 1. ê³µë°± ì œê±°
        size = size.strip()
        
        # 2. ê´„í˜¸ ì œê±° í›„ ë‹¤ì‹œ ì¶”ê°€ (ì¼ê´€ëœ í˜•ì‹ìœ¼ë¡œ)
        # "L 24~36" â†’ "L(24~36)"
        # "L(24-36)" â†’ "L(24~36)"
        
        # ì‚¬ì´ì¦ˆ ì½”ë“œì™€ ìˆ«ì ë²”ìœ„ ë¶„ë¦¬
        match = re.match(r'^([A-Z]+)\s*[\(]?([0-9]+)\s*[-~]\s*([0-9]+)\s*[\)]?$', size)
        if match:
            size_code = match.group(1)
            start_num = match.group(2)
            end_num = match.group(3)
            return f"{size_code}({start_num}~{end_num})"
        
        # 3. ê¸°í˜¸ í†µì¼ (~ë¡œ í†µì¼)
        size = size.replace('-', '~')
        
        # 4. ê´„í˜¸ê°€ ì—†ëŠ” ê²½ìš° ì¶”ê°€
        if '(' not in size and '~' in size:
            # "L 24~36" â†’ "L(24~36)"
            parts = size.split('~')
            if len(parts) == 2:
                size_code = parts[0].strip().split()[-1]  # ë§ˆì§€ë§‰ ë‹¨ì–´ê°€ ì‚¬ì´ì¦ˆ ì½”ë“œ
                return f"{size_code}({parts[0].strip().replace(size_code, '').strip()}~{parts[1].strip()})"
        
        return size

    def check_size_match(self, upload_size: str, brand_size_pattern: str) -> float:
        """
        ì‚¬ì´ì¦ˆ ì •í™• ë§¤ì¹­ ì²´í¬ (ì˜¤ë§¤ì¹­ ë°©ì§€ ê°•í™” + ì£¼ë‹ˆì–´ ì‚¬ì´ì¦ˆ ì°¨ë‹¨)
        
        ì›ë¦¬:
        - [M]ê³¼ [JM]ì„ ëª…í™•íˆ êµ¬ë¶„
        - "M"ì€ [M] íŒ¨í„´ì´ ìˆì–´ì•¼ë§Œ 100% ë§¤ì¹­
        - "M"ì´ "JM"ì— í¬í•¨ë˜ëŠ” ê²½ìš°ëŠ” 0ì  (ì£¼ë‹ˆì–´ ì°¨ë‹¨)
        - ì„±ì¸ ì‚¬ì´ì¦ˆ(S, M, L, XL)ì™€ ì£¼ë‹ˆì–´ ì‚¬ì´ì¦ˆ(JS, JM, JL, JXL)ë¥¼ ëª…ì‹œì ìœ¼ë¡œ êµ¬ë¶„
        
        ì˜ˆì‹œ:
        - "M" vs "[M][L][XL]" â†’ 100% (ì •í™• ë§¤ì¹­)
        - "M" vs "[JM][JS]" â†’ 0% (ì£¼ë‹ˆì–´ ì°¨ë‹¨)
        - "S" vs "[S][M][L]" â†’ 100% (ì •í™• ë§¤ì¹­)
        - "S" vs "[JS][JM]" â†’ 0% (ì£¼ë‹ˆì–´ ì°¨ë‹¨)
        """
        if not upload_size or not brand_size_pattern:
            return 0.0
        
        # ì‚¬ì´ì¦ˆ í˜•ì‹ ì •ê·œí™”
        upload_size = self.normalize_size_format(upload_size.strip().upper())
        brand_size_pattern = brand_size_pattern.upper()
        
        import re
        
        # ğŸš¨ ì£¼ë‹ˆì–´ ì‚¬ì´ì¦ˆ ëª…ì‹œì  ì°¨ë‹¨ (ì„±ì¸/ì£¼ë‹ˆì–´ í˜¼ë™ ë°©ì§€)
        # S â†’ JS ì°¨ë‹¨ (JSë§Œ ìˆê³  ë…ë¦½ì ì¸ Sê°€ ì—†ëŠ” ê²½ìš°)
        if upload_size == 'S':
            # JSê°€ ìˆëŠ”ì§€ í™•ì¸
            if 'JS' in brand_size_pattern:
                # ë…ë¦½ì ì¸ Sê°€ ìˆëŠ”ì§€ í™•ì¸ ([S] ë˜ëŠ” ê³µë°± S ê³µë°±)
                has_independent_s = (
                    re.search(r'\[S\]', brand_size_pattern) or
                    re.search(r'\bS\b', brand_size_pattern.replace('JS', ''))
                )
                if not has_independent_s:
                    return 0.0  # âŒ JSë§Œ ìˆê³  Sê°€ ì—†ìŒ â†’ ì£¼ë‹ˆì–´ ì „ìš© â†’ ì°¨ë‹¨
        
        # M â†’ JM ì°¨ë‹¨
        if upload_size == 'M':
            if 'JM' in brand_size_pattern:
                has_independent_m = (
                    re.search(r'\[M\]', brand_size_pattern) or
                    re.search(r'\bM\b', brand_size_pattern.replace('JM', ''))
                )
                if not has_independent_m:
                    return 0.0  # âŒ JMë§Œ ìˆê³  Mì´ ì—†ìŒ â†’ ì£¼ë‹ˆì–´ ì „ìš© â†’ ì°¨ë‹¨
        
        # L â†’ JL ì°¨ë‹¨
        if upload_size == 'L':
            if 'JL' in brand_size_pattern:
                has_independent_l = (
                    re.search(r'\[L\]', brand_size_pattern) or
                    re.search(r'\bL\b', brand_size_pattern.replace('JL', '').replace('XL', '').replace('XXL', ''))
                )
                if not has_independent_l:
                    return 0.0  # âŒ JLë§Œ ìˆê³  Lì´ ì—†ìŒ â†’ ì£¼ë‹ˆì–´ ì „ìš© â†’ ì°¨ë‹¨
        
        # XL â†’ JXL ì°¨ë‹¨
        if upload_size == 'XL':
            if 'JXL' in brand_size_pattern:
                has_independent_xl = (
                    re.search(r'\[XL\]', brand_size_pattern) or
                    re.search(r'\bXL\b', brand_size_pattern.replace('JXL', ''))
                )
                if not has_independent_xl:
                    return 0.0  # âŒ JXLë§Œ ìˆê³  XLì´ ì—†ìŒ â†’ ì£¼ë‹ˆì–´ ì „ìš© â†’ ì°¨ë‹¨
        
        # 1. ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­ ([M] í˜•íƒœë¡œ ì¡´ì¬í•´ì•¼ í•¨)
        exact_pattern = re.search(rf'\[{re.escape(upload_size)}\]', brand_size_pattern)
        if exact_pattern:
            return 100.0  # âœ… ì •í™•íˆ ì¼ì¹˜!
        
        # 2. ê´„í˜¸ê°€ í¬í•¨ëœ ì‚¬ì´ì¦ˆ ë§¤ì¹­ (ìƒˆë¡œ ì¶”ê°€)
        # ì˜ˆ: "S(10~18)" vs "S(10~18)" ë˜ëŠ” "S(10~18)" vs "S(10~18)|M(18~24)"
        if upload_size in brand_size_pattern:
            return 100.0  # âœ… ê´„í˜¸ í¬í•¨ ì‚¬ì´ì¦ˆ ë§¤ì¹­!
        
        # 3. ì‚¬ì´ì¦ˆ ì½”ë“œë§Œ ì¶”ì¶œí•˜ì—¬ ë§¤ì¹­
        # ì˜ˆ: "S(10~18)" â†’ "S" ì¶”ì¶œ
        upload_size_code = upload_size.split('(')[0] if '(' in upload_size else upload_size
        brand_size_codes = re.findall(r'\b([A-Z]+)(?:\d+)?\b', brand_size_pattern)
        
        if upload_size_code in brand_size_codes:
            return 100.0  # âœ… ì‚¬ì´ì¦ˆ ì½”ë“œ ë§¤ì¹­!
        
        # 4. ê´„í˜¸ ì—†ì´ ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ëœ ê²½ìš°
        # "M L XL" í˜•íƒœ
        if f' {upload_size} ' in f' {brand_size_pattern} ':
            return 100.0
        
        # 5. ê´„í˜¸ ì œê±° í›„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë§¤ì¹­
        # "(XS)[S][M][L][XL]" â†’ "XS S M L XL"
        cleaned = re.sub(r'[\[\]()]', ' ', brand_size_pattern)
        size_tokens = [s.strip() for s in cleaned.split() if s.strip()]
        
        if upload_size in size_tokens:
            return 100.0  # âœ… ë‹¨ì–´ë¡œ ì •í™•íˆ ì¼ì¹˜
        
        # 4. ë¶€ë¶„ ì¼ì¹˜ëŠ” 0ì  (ë” ì—„ê²©í•˜ê²Œ - ì£¼ë‹ˆì–´ í˜¼ë™ ë°©ì§€)
        if upload_size in brand_size_pattern:
            return 0.0  # âŒ ë¶€ë¶„ ì¼ì¹˜ ì°¨ë‹¨ (20.0 â†’ 0.0)
        
        # 5. ì „í˜€ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ
        return 0.0
    
    def calculate_price_similarity(self, upload_price, brand_price) -> float:
        """
        ê°€ê²© ìœ ì‚¬ë„ ê³„ì‚° (ì˜¤ë§¤ì¹­ ë°©ì§€)
        
        ì›ë¦¬:
        - ê°€ê²©ì´ ì •í™•íˆ ì¼ì¹˜í•˜ë©´ 100ì 
        - Â±5% ì´ë‚´ë©´ 90ì 
        - Â±10% ì´ë‚´ë©´ 70ì 
        - 10% ì´ˆê³¼ ì°¨ì´ëŠ” 0ì  (ë‹¤ë¥¸ ìƒí’ˆì¼ ê°€ëŠ¥ì„±)
        
        ì˜ˆì‹œ:
        - 18000 vs 18000 â†’ 100%
        - 18000 vs 18900 â†’ 90% (5% ì°¨ì´)
        - 18000 vs 20000 â†’ 0% (11% ì°¨ì´)
        """
        # ê°€ê²© ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¤‘ë¦½
        try:
            upload_price = float(upload_price) if upload_price else 0
            brand_price = float(brand_price) if brand_price else 0
        except (ValueError, TypeError):
            return 50.0  # ì¤‘ë¦½
        
        if upload_price <= 0 or brand_price <= 0:
            return 50.0  # ê°€ê²© ì •ë³´ ì—†ìŒ - ì¤‘ë¦½
        
        # ê°€ê²© ì°¨ì´ ë¹„ìœ¨ ê³„ì‚°
        price_diff = abs(upload_price - brand_price) / brand_price * 100
        
        if price_diff == 0:
            return 100.0  # âœ… ì •í™•íˆ ì¼ì¹˜
        elif price_diff <= 5:
            return 90.0   # Â±5% ì´ë‚´
        elif price_diff <= 10:
            return 70.0   # Â±10% ì´ë‚´
        else:
            return 0.0    # âŒ 10% ì´ˆê³¼ - ë‹¤ë¥¸ ìƒí’ˆì¼ ê°€ëŠ¥ì„±
    
    def save_keywords(self):
        """í˜„ì¬ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            keyword_file = "keywords.xlsx"
            df = pd.DataFrame({'í‚¤ì›Œë“œ': self.keyword_list})
            df.to_excel(keyword_file, index=False)
            logger.info(f"í‚¤ì›Œë“œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {len(self.keyword_list)}ê°œ í‚¤ì›Œë“œ")
            return True
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def add_keyword(self, keyword: str) -> bool:
        """í‚¤ì›Œë“œ ì¶”ê°€"""
        keyword = keyword.strip()
        if keyword and keyword not in self.keyword_list:
            self.keyword_list.append(keyword)
            return self.save_keywords()
        return False

    def remove_keyword(self, keyword: str) -> bool:
        """í‚¤ì›Œë“œ ì œê±°"""
        if keyword in self.keyword_list:
            self.keyword_list.remove(keyword)
            return self.save_keywords()
        return False

    def extract_third_word_from_address(self, address: str) -> str:
        """ì£¼ì†Œì—ì„œ 3ë²ˆì§¸ ë‹¨ì–´ ì¶”ì¶œ (ë„ì–´ì“°ê¸° ê¸°ì¤€)"""
        if not address or pd.isna(address):
            return ""
        
        address = str(address).strip()
        words = address.split()
        
        # 3ë²ˆì§¸ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ë°˜í™˜, ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´
        if len(words) >= 3:
            return words[2]
        return ""

    def normalize_product_name(self, name: str) -> str:
        """ìƒí’ˆëª… ì •ê·œí™” - ìºì‹œ ë° ë©”ëª¨ë¦¬ ìµœì í™” ë²„ì „"""
        if not name or pd.isna(name):
            return ""
        
        name_str = str(name).strip()
        if not name_str:
            return ""
        
        # ìºì‹œ í™•ì¸
        with self._cache_lock:
            if name_str in self._normalized_cache:
                return self._normalized_cache[name_str]
        
        # ì •ê·œí™” ì²˜ë¦¬
        try:
            normalized = name_str.lower()
            
            # âš¡ ìµœìš°ì„ : ìƒí’ˆëª… í‚¤ì›Œë“œ ì¶”ì¶œ (ì‚¬ì´ì¦ˆ í‘œê¸° ì œê±°)
            # ëª©ì : "ìŠ¤ì»¤íŠ¸(XS~XL)" â†’ "ìŠ¤ì»¤íŠ¸" (ë§¤ì¹­ë¥  í–¥ìƒ)
            # (S(3~4)~XL(7~8)) â†’ ë¹ˆ ë¬¸ìì—´
            # ëŸ¬ë¸”ë¦¬ì–‘ë§(S~XL) â†’ ëŸ¬ë¸”ë¦¬ì–‘ë§
            # í‹°ì…”ì¸ (FREE) â†’ í‹°ì…”ì¸ 
            import re
            normalized = re.sub(r'\([^()]*\)', '', normalized)  # 1ì°¨: ë‚´ë¶€ ê´„í˜¸ ì œê±°
            normalized = re.sub(r'\([^()]*\)', '', normalized)  # 2ì°¨: ì™¸ë¶€ ê´„í˜¸ ì œê±°
            normalized = re.sub(r'\([^()]*\)', '', normalized)  # 3ì°¨: ì¤‘ì²© ê´„í˜¸ ëŒ€ë¹„
            
            # ë‚˜ë¨¸ì§€ íŒ¨í„´ ì²˜ë¦¬
            if 'brackets' in self._compiled_patterns:
                normalized = self._compiled_patterns['brackets'].sub('', normalized)
            if 'braces' in self._compiled_patterns:
                normalized = self._compiled_patterns['braces'].sub('', normalized)
            if 'special_chars' in self._compiled_patterns:
                normalized = self._compiled_patterns['special_chars'].sub(' ', normalized)
            if 'multiple_spaces' in self._compiled_patterns:
                normalized = self._compiled_patterns['multiple_spaces'].sub(' ', normalized)
            
            normalized = normalized.strip()
            
            # í‚¤ì›Œë“œ ì œê±° (ë‹¨ìˆœí™” - ê´„í˜¸ëŠ” ì´ë¯¸ ì œê±°ë¨)
            if self.keyword_list:
                # ì¼ë°˜ í‚¤ì›Œë“œë§Œ ì œê±° (ê´„í˜¸ ì•ˆì˜ ì‚¬ì´ì¦ˆ íŒ¨í„´ì€ ì´ë¯¸ ì œê±°ë¨)
                for keyword in self.keyword_list:
                    if not keyword or keyword.startswith('*'):
                        continue
                    
                    # ë‹¨ë… í‚¤ì›Œë“œ ì œê±°
                    keyword_pattern = self._get_keyword_pattern(keyword)
                    normalized = keyword_pattern.sub('', normalized)
                
                # í…ìŠ¤íŠ¸ ì •ë¦¬
                if 'comma_spaces' in self._compiled_patterns:
                    normalized = self._compiled_patterns['comma_spaces'].sub(',', normalized)
                if 'multiple_commas' in self._compiled_patterns:
                    normalized = self._compiled_patterns['multiple_commas'].sub(',', normalized)
                if 'multiple_spaces' in self._compiled_patterns:
                    normalized = self._compiled_patterns['multiple_spaces'].sub(' ', normalized)
                
                normalized = normalized.strip(',').strip()
            
            # ê²°ê³¼ ê²€ì¦
            if len(normalized) < 2 or ('korean_alpha_num' in self._compiled_patterns and 
                                      not self._compiled_patterns['korean_alpha_num'].search(normalized)):
                normalized = name_str.lower()
            
            # ìºì‹œì— ì €ì¥ (í¬ê¸° ì œí•œ í™•ì¸)
            with self._cache_lock:
                # âš¡ ë°ë“œë½ ë°©ì§€: Lock ì•ˆì—ì„œ ì§ì ‘ ì •ë¦¬ (ì¤‘ì²© Lock ë°©ì§€)
                if len(self._normalized_cache) >= self._max_cache_size:
                    # ì˜¤ë˜ëœ í•­ëª©ì˜ ì ˆë°˜ ì œê±°
                    items_to_remove = len(self._normalized_cache) // 2
                    keys_to_remove = list(self._normalized_cache.keys())[:items_to_remove]
                    for key in keys_to_remove:
                        del self._normalized_cache[key]
                
                self._normalized_cache[name_str] = normalized
            
            return normalized
            
        except Exception as e:
            logger.error(f"ìƒí’ˆëª… ì •ê·œí™” ì‹¤íŒ¨ ({name_str}): {e}")
            return name_str.lower()

    @lru_cache(maxsize=200)
    def parse_color_variants(self, color_text: str) -> tuple:
        """ìƒ‰ìƒ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ê°€ëŠ¥í•œ ë³€í˜•ì„ ì¶”ì¶œ - ìºì‹œ ë²„ì „"""
        if not color_text or pd.isna(color_text):
            return ()
        
        color_text = str(color_text).strip()
        variants = set()
        
        # ê¸°ë³¸ ìƒ‰ìƒ ì¶”ê°€
        variants.add(color_text.lower())
        
        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ìƒ‰ìƒë“¤ ì²˜ë¦¬
        if ',' in color_text:
            colors = [c.strip().lower() for c in color_text.split(',') if c.strip()]
            variants.update(colors)
        
        # ìŠ¬ë˜ì‹œë¡œ êµ¬ë¶„ëœ ìƒ‰ìƒë“¤ ì²˜ë¦¬
        if '/' in color_text:
            colors = [c.strip().lower() for c in color_text.split('/') if c.strip()]
            variants.update(colors)
        
        # ê´„í˜¸ ì œê±° ë²„ì „
        no_parentheses = self._compiled_patterns['parentheses'].sub('', color_text).strip().lower()
        if no_parentheses:
            variants.add(no_parentheses)
        
        return tuple(sorted(variants))

    @lru_cache(maxsize=200)
    def parse_size_variants(self, size_text: str) -> tuple:
        """ì‚¬ì´ì¦ˆ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ê°€ëŠ¥í•œ ë³€í˜•ì„ ì¶”ì¶œ - ìºì‹œ ë²„ì „"""
        if not size_text or pd.isna(size_text):
            return ()
        
        size_text = str(size_text).strip()
        variants = set()
        
        # ê¸°ë³¸ ì‚¬ì´ì¦ˆ ì¶”ê°€
        variants.add(size_text.lower())
        
        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì‚¬ì´ì¦ˆë“¤ ì²˜ë¦¬
        if ',' in size_text:
            sizes = [s.strip().lower() for s in size_text.split(',') if s.strip()]
            variants.update(sizes)
        
        # ìŠ¬ë˜ì‹œë¡œ êµ¬ë¶„ëœ ì‚¬ì´ì¦ˆë“¤ ì²˜ë¦¬  
        if '/' in size_text:
            sizes = [s.strip().lower() for s in size_text.split('/') if s.strip()]
            variants.update(sizes)
        
        # ê´„í˜¸ ì œê±° ë²„ì „
        no_parentheses = self._compiled_patterns['parentheses'].sub('', size_text).strip().lower()
        if no_parentheses:
            variants.add(no_parentheses)
        
        return tuple(sorted(variants))

    def load_brand_data(self):
        """ë¸Œëœë“œë§¤ì¹­ì‹œíŠ¸ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        try:
            self.brand_data = brand_sheets_api.read_brand_matching_data()
            logger.info(f"ë¸Œëœë“œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.brand_data)}ê°œ ìƒí’ˆ")
            
            # ë°ì´í„° ë¡œë“œ í›„ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• (ì†ë„ ìµœì í™”)
            self._build_brand_index()
            
        except Exception as e:
            logger.error(f"ë¸Œëœë“œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.brand_data = pd.DataFrame()
            self.brand_index = {}

    def parse_options(self, option_text: str) -> tuple:
        """ì˜µì…˜ í…ìŠ¤íŠ¸ì—ì„œ ìƒ‰ìƒê³¼ ì‚¬ì´ì¦ˆ ì¶”ì¶œ - ìµœì í™” ë²„ì „"""
        if not option_text or pd.isna(option_text) or str(option_text).strip().lower() == 'nan':
            return "", ""
        
        option_text = str(option_text).strip()
        color = ""
        size = ""
        
        # ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©
        color_keywords = self._compiled_patterns['color_keywords']
        size_keywords = self._compiled_patterns['size_keywords']
        
        # íŒ¨í„´ 1: ìƒ‰ìƒ=ê°’, ì‚¬ì´ì¦ˆ=ê°’ (ë“±í˜¸ ì‚¬ìš©)
        color_match = re.search(color_keywords.pattern + r'\s*=\s*([^,/]+?)(?:\s*[,/]|\s*(?:ì‚¬ì´ì¦ˆ|Size)|$)', 
                               option_text, re.IGNORECASE)
        if color_match:
            color = color_match.group(1).strip()
        
        size_match = re.search(size_keywords.pattern + r'\s*[=:]\s*([^,/]+?)(?:\s*[,/]|$)', 
                              option_text, re.IGNORECASE)
        if size_match:
            size = size_match.group(1).strip()
        
        # íŒ¨í„´ 2: ìƒ‰ìƒ: ê°’, ì‚¬ì´ì¦ˆ: ê°’ (ì½œë¡  ì‚¬ìš©)
        if not color:
            color_match = re.search(color_keywords.pattern + r'\s*:\s*([^,/]+?)(?:\s*[,/]|\s*(?:ì‚¬ì´ì¦ˆ|Size)|$)', 
                                   option_text, re.IGNORECASE)
            if color_match:
                color = color_match.group(1).strip()
        
        if not size:
            size_match = re.search(size_keywords.pattern + r'\s*:\s*([^,/]+?)(?:\s*[,/]|$)', 
                                  option_text, re.IGNORECASE)
            if size_match:
                size = size_match.group(1).strip()
        
        # íŒ¨í„´ 3: ìƒ‰ìƒ/ì‚¬ì´ì¦ˆ (ìŠ¬ë˜ì‹œë¡œ êµ¬ë¶„)
        if not color and not size:
            slash_match = self._compiled_patterns['slash_pattern'].match(option_text.strip())
            if slash_match:
                potential_color = slash_match.group(1).strip()
                potential_size = slash_match.group(2).strip()
                if self._compiled_patterns['size_check'].search(potential_size):
                    color = potential_color
                    size = potential_size
        
        # íŒ¨í„´ 4: ë‹¨ì–´-ìˆ«ì í˜•íƒœ
        if not color and not size:
            dash_match = self._compiled_patterns['dash_pattern'].match(option_text.strip())
            if dash_match:
                part1 = dash_match.group(1).strip()
                part2 = dash_match.group(2).strip()
                
                if self._compiled_patterns['exact_size'].match(part1):
                    size = part1
                    color = part2
                elif self._compiled_patterns['size_check'].search(part2):
                    color = part1
                    size = part2
        
        # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°
        if color:
            color = re.sub(r'\s*[/\\|]+\s*$', '', color).strip()
        if size:
            size = re.sub(r'\s*[/\\|]+\s*$', '', size).strip()
        
        return color, size

    def find_similar_products_for_failed_matches(self, failed_products: List[Dict]) -> pd.DataFrame:
        """ë§¤ì¹­ ì‹¤íŒ¨í•œ ìƒí’ˆë“¤ì— ëŒ€í•´ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ ìˆ˜í–‰ - ì„±ëŠ¥ ìµœì í™”"""
        import time
        start_time = time.time()
        
        logger.info(f"ë§¤ì¹­ ì‹¤íŒ¨ ìƒí’ˆ {len(failed_products)}ê°œì— ëŒ€í•´ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œì‘")
        
        if self.brand_data is None or self.brand_data.empty:
            logger.error("ë¸Œëœë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()
        
        results = []
        total_failed = len(failed_products)
        
        for i, failed_product in enumerate(failed_products):
            # ì§„í–‰ë¥  í‘œì‹œ (10ê°œë§ˆë‹¤)
            if i % 10 == 0 and i > 0:
                elapsed = time.time() - start_time
                progress = (i / total_failed) * 100
                logger.info(f"ìœ ì‚¬ë„ ë§¤ì¹­ ì§„í–‰ë¥ : {i}/{total_failed} ({progress:.1f}%) - ê²½ê³¼ì‹œê°„: {elapsed:.1f}ì´ˆ")
                
                # íƒ€ì„ì•„ì›ƒ ì²´í¬ (10ë¶„)
                if elapsed > 600:
                    logger.error("ìœ ì‚¬ë„ ë§¤ì¹­ íƒ€ì„ì•„ì›ƒ (10ë¶„ ì´ˆê³¼)")
                    break
            logger.debug(f"ìœ ì‚¬ë„ ë§¤ì¹­ ì§„í–‰: {i+1}/{len(failed_products)}")
            
            # ì‹¤íŒ¨í•œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
            brand = failed_product.get('ë¸Œëœë“œ', '').strip()
            product_name = failed_product.get('ìƒí’ˆëª…', '').strip()
            color = failed_product.get('ìƒ‰ìƒ', '').strip()
            size = failed_product.get('ì‚¬ì´ì¦ˆ', '').strip()
            
            # ìƒí’ˆëª… ì •ê·œí™”
            normalized_product_name = self.normalize_product_name(product_name)
            
            best_match = None
            best_score = 0.0
            
            # âš¡ ì†ë„ ìµœì í™”: ë¸Œëœë“œ ì¸ë±ìŠ¤ í™œìš© (row ë°ì´í„° ì§ì ‘ ì‚¬ìš©)
            candidate_rows = []
            if brand:
                brand_lower = brand.lower()
                candidate_rows = self.brand_index.get(brand_lower, [])
            
            # ë¸Œëœë“œ ì—†ê±°ë‚˜ ì¸ë±ìŠ¤ì— ì—†ìœ¼ë©´ ìŠ¤í‚µ (ìœ ì‚¬ë„ ë§¤ì¹­ì€ ì œí•œì ìœ¼ë¡œ)
            if not candidate_rows:
                logger.debug(f"ìœ ì‚¬ë„ ë§¤ì¹­ ìŠ¤í‚µ: ë¸Œëœë“œ '{brand}' ì¸ë±ìŠ¤ì— ì—†ìŒ")
                continue
            
            # ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ 50ê°œë¡œ ì œí•œ
            if len(candidate_rows) > 50:
                candidate_rows = candidate_rows[:50]
            
            logger.debug(f"âš¡ ìœ ì‚¬ë„ ë§¤ì¹­ ëŒ€ìƒ: {len(candidate_rows)}ê°œ ìƒí’ˆ")
            
            processed_count = 0
            row_start_time = time.time()
            for brand_row_dict in candidate_rows:
                
                processed_count += 1
                
                # íƒ€ì„ì•„ì›ƒ ì²´í¬ (ê°œë³„ ìƒí’ˆë‹¹ 5ì´ˆ)
                if time.time() - row_start_time > 5:
                    logger.warning(f"âš ï¸  ìœ ì‚¬ë„ ë§¤ì¹­ íƒ€ì„ì•„ì›ƒ (5ì´ˆ): {brand} - {product_name[:30]}... ({processed_count}ê°œ ì²˜ë¦¬ë¨)")
                    break
                
                # ë¬´í•œ ë£¨í”„ ë°©ì§€: ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ (30ê°œë¡œ ì œí•œ)
                if processed_count > 30:
                    logger.warning(f"âš ï¸  ìœ ì‚¬ë„ ë§¤ì¹­ ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ (30ê°œ): {brand} - {product_name[:30]}...")
                    break
                
                brand_brand = str(brand_row_dict.get('ë¸Œëœë“œ', '')).strip()
                brand_product = str(brand_row_dict.get('ìƒí’ˆëª…', '')).strip()
                brand_options = str(brand_row_dict.get('ì˜µì…˜ì…ë ¥', '')).strip()
                
                # ìƒí’ˆëª… ìœ ì‚¬ë„ ê³„ì‚°
                brand_normalized = self.normalize_product_name(brand_product)
                product_similarity = self.calculate_string_similarity(normalized_product_name, brand_normalized)
                
                # ìƒí’ˆëª… ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ìŠ¤í‚µ (ì„ê³„ê°’: 0.3)
                if product_similarity < 0.3:
                    continue
                
                # ìƒ‰ìƒ/ì‚¬ì´ì¦ˆ ìœ ì‚¬ë„ ê³„ì‚°
                color_similarity = 0.0
                size_similarity = 0.0
                
                if color or size:
                    # ë¸Œëœë“œ ìƒí’ˆì˜ ìƒ‰ìƒ/ì‚¬ì´ì¦ˆ ì¶”ì¶œ
                    brand_color = self.extract_color(brand_options)
                    brand_size = self.extract_size(brand_options)
                    
                    if color and brand_color:
                        # ìƒ‰ìƒ ë³€í˜•ë“¤ê³¼ ë¹„êµ
                        color_variants = self.parse_color_variants(color)
                        brand_color_variants = self.parse_color_variants(brand_color)
                        
                        max_color_sim = 0.0
                        for c1 in color_variants:
                            for c2 in brand_color_variants:
                                sim = self.calculate_color_similarity(c1, c2)
                                max_color_sim = max(max_color_sim, sim)
                        color_similarity = max_color_sim
                    
                    if size and brand_size:
                        # ì‚¬ì´ì¦ˆ ë³€í˜•ë“¤ê³¼ ë¹„êµ
                        size_variants = self.parse_size_variants(size)
                        brand_size_variants = self.parse_size_variants(brand_size)
                        
                        max_size_sim = 0.0
                        for s1 in size_variants:
                            for s2 in brand_size_variants:
                                sim = self.calculate_size_similarity(s1, s2)
                                max_size_sim = max(max_size_sim, sim)
                        size_similarity = max_size_sim
                
                # ì¢…í•© ìœ ì‚¬ë„ ê³„ì‚° (ê°€ì¤‘í‰ê· )
                # ìƒí’ˆëª… 60%, ìƒ‰ìƒ 20%, ì‚¬ì´ì¦ˆ 20%
                total_score = (product_similarity * 0.6 + 
                              color_similarity * 0.2 + 
                              size_similarity * 0.2)
                
                # ìƒ‰ìƒì´ë‚˜ ì‚¬ì´ì¦ˆê°€ ì—†ëŠ” ê²½ìš° ìƒí’ˆëª… ë¹„ì¤‘ ì¦ê°€
                if not color and not size:
                    total_score = product_similarity
                elif not color:
                    total_score = product_similarity * 0.8 + size_similarity * 0.2
                elif not size:
                    total_score = product_similarity * 0.8 + color_similarity * 0.2
                
                # ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸
                if total_score > best_score:
                    best_score = total_score
                    best_match = {
                        'brand_brand': brand_brand,
                        'brand_product': brand_product,
                        'brand_wholesale': brand_row_dict.get('ì¤‘ë„ë§¤', ''),
                        'brand_supply': brand_row_dict.get('ê³µê¸‰ê°€', ''),
                        'brand_options': brand_options,
                        'product_similarity': product_similarity,
                        'color_similarity': color_similarity,
                        'size_similarity': size_similarity,
                        'total_score': total_score
                    }
            
            # ê²°ê³¼ ì €ì¥
            result_row = {
                'ì›ë³¸_ë¸Œëœë“œ': brand,
                'ì›ë³¸_ìƒí’ˆëª…': product_name,
                'ì›ë³¸_ìƒ‰ìƒ': color,
                'ì›ë³¸_ì‚¬ì´ì¦ˆ': size,
                'ìœ ì‚¬ìƒí’ˆ_ë¸Œëœë“œ': best_match['brand_brand'] if best_match else '',
                'ìœ ì‚¬ìƒí’ˆ_ìƒí’ˆëª…': best_match['brand_product'] if best_match else '',
                'ìœ ì‚¬ìƒí’ˆ_ì¤‘ë„ë§¤': best_match['brand_wholesale'] if best_match else '',
                'ìœ ì‚¬ìƒí’ˆ_ê³µê¸‰ê°€': best_match['brand_supply'] if best_match else '',
                'ìœ ì‚¬ìƒí’ˆ_ì˜µì…˜': best_match['brand_options'] if best_match else '',
                'ìƒí’ˆëª…_ìœ ì‚¬ë„': f"{best_match['product_similarity']:.3f}" if best_match else '0.000',
                'ìƒ‰ìƒ_ìœ ì‚¬ë„': f"{best_match['color_similarity']:.3f}" if best_match else '0.000',
                'ì‚¬ì´ì¦ˆ_ìœ ì‚¬ë„': f"{best_match['size_similarity']:.3f}" if best_match else '0.000',
                'ì¢…í•©_ìœ ì‚¬ë„': f"{best_match['total_score']:.3f}" if best_match else '0.000',
                'ë§¤ì¹­_ìƒíƒœ': 'ìœ ì‚¬ë§¤ì¹­' if best_match and best_match['total_score'] >= 0.3 else 'ë§¤ì¹­ì‹¤íŒ¨'
            }
            
            # ì›ë³¸ ë°ì´í„°ì˜ ë‹¤ë¥¸ ì»¬ëŸ¼ë“¤ë„ ì¶”ê°€
            for key, value in failed_product.items():
                if key not in result_row:
                    result_row[f'ì›ë³¸_{key}'] = value
            
            results.append(result_row)
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        result_df = pd.DataFrame(results)
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        if not result_df.empty:
            result_df = result_df.sort_values('ì¢…í•©_ìœ ì‚¬ë„', ascending=False)
        
        total_elapsed = time.time() - start_time
        successful_matches = len(result_df[result_df['ë§¤ì¹­_ìƒíƒœ'] == 'ìœ ì‚¬ë§¤ì¹­']) if not result_df.empty else 0
        logger.info(f"ìœ ì‚¬ë„ ë§¤ì¹­ ì™„ë£Œ: {len(result_df)}ê°œ ê²°ê³¼ ({successful_matches}ê°œ ì„±ê³µ) - ì†Œìš”ì‹œê°„: {total_elapsed:.1f}ì´ˆ")
        return result_df

    def _process_batch(self, batch_data):
        """ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬ (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
        results = []
        for row_data in batch_data:
            result = self._process_single_row(row_data)
            results.append(result)
        return results
    
    def _process_single_row(self, row_data):
        """ë‹¨ì¼ í–‰ ì²˜ë¦¬ (ë³‘ë ¬ ì²˜ë¦¬ìš© í—¬í¼ í•¨ìˆ˜)"""
        # ê¸°ì¡´ convert_sheet1_to_sheet2ì˜ ë‹¨ì¼ í–‰ ì²˜ë¦¬ ë¡œì§ì„ ì—¬ê¸°ë¡œ ì´ë™
        # (ì‹¤ì œ êµ¬í˜„ì€ ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼)
        pass
    
    def convert_sheet1_to_sheet2(self, sheet1_df: pd.DataFrame) -> pd.DataFrame:
        """Sheet1 í˜•ì‹ì„ Sheet2 í˜•ì‹ìœ¼ë¡œ ë³€í™˜ - ì„±ëŠ¥ ìµœì í™” ë²„ì „"""
        import time
        start_time = time.time()
        
        logger.info(f"Sheet1 -> Sheet2 ë³€í™˜ ì‹œì‘: {len(sheet1_df):,}ê°œ í–‰ ì²˜ë¦¬")

        # Sheet2 í˜•ì‹ì˜ 23ê°œ ì»¬ëŸ¼ ìƒì„±
        sheet2_columns = [
            'Aì—´(ã…‡)', 'Bì—´(ë¯¸ë“±ë¡ì£¼ë¬¸)', 'Cì—´(ì£¼ë¬¸ì¼)', 'Dì—´(ì•„ì´ë””ì£¼ë¬¸ë²ˆí˜¸)', 'Eì—´(ã…‡)',
            'Fì—´(ì£¼ë¬¸ìëª…)', 'Gì—´(ìœ„íƒìëª…)', 'Hì—´(ë¸Œëœë“œ)', 'Iì—´(ìƒí’ˆëª…)', 'Jì—´(ìƒ‰ìƒ)',
            'Kì—´(ì‚¬ì´ì¦ˆ)', 'Lì—´(ìˆ˜ëŸ‰)', 'Mì—´(ì˜µì…˜ê°€)', 'Nì—´(ì¤‘ë„ë§¤ëª…)', 'Oì—´(ë„ë§¤ê°€ê²©)',
            'Pì—´(ë¯¸ì†¡)', 'Qì—´(ë¹„ê³ )', 'Rì—´(ì´ë¦„)', 'Sì—´(ì „í™”ë²ˆí˜¸)', 'Tì—´(ì£¼ì†Œ)',
            'Uì—´(ì•„ì´ë””)', 'Vì—´(ë°°ì†¡ë©”ì„¸ì§€)', 'Wì—´(ê¸ˆì•¡)'
        ]

        if sheet1_df.empty:
            logger.warning("ì—…ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame(columns=sheet2_columns)

        # ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ë“  í–‰ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ (ì„±ëŠ¥ ìµœì í™”)
        sheet2_rows = []
        total_rows = len(sheet1_df)

        # Sheet1ì˜ ë°ì´í„°ë¥¼ Sheet2ë¡œ ë§¤í•‘
        for i, (idx, row) in enumerate(sheet1_df.iterrows()):
            # ì§„í–‰ë¥  í‘œì‹œ (1000ê°œë§ˆë‹¤)
            if i % 1000 == 0 and i > 0:
                elapsed = time.time() - start_time
                progress = (i / total_rows) * 100
                logger.info(f"ë³€í™˜ ì§„í–‰ë¥ : {i:,}/{total_rows:,} ({progress:.1f}%) - ê²½ê³¼ì‹œê°„: {elapsed:.1f}ì´ˆ")
                
                # íƒ€ì„ì•„ì›ƒ ì²´í¬ (10ë¶„)
                if elapsed > 600:
                    logger.error("ë°ì´í„° ë³€í™˜ íƒ€ì„ì•„ì›ƒ (10ë¶„ ì´ˆê³¼)")
                    break
            sheet2_row = {}
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            for col in sheet2_columns:
                sheet2_row[col] = ""
            
            # ì§ì ‘ ë§¤í•‘
            if len(sheet1_df.columns) >= 1:  # ì—…ë¡œë“œ Aì—´ â†’ Sheet2 Cì—´ (ì£¼ë¬¸ì¼)
                sheet2_row['Cì—´(ì£¼ë¬¸ì¼)'] = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
            
            if len(sheet1_df.columns) >= 2:  # ì—…ë¡œë“œ Bì—´ â†’ Sheet2 Dì—´ (ì•„ì´ë””/ì£¼ë¬¸ë²ˆí˜¸)
                sheet2_row['Dì—´(ì•„ì´ë””ì£¼ë¬¸ë²ˆí˜¸)'] = str(row.iloc[1]) if pd.notna(row.iloc[1]) else ""
            
            if len(sheet1_df.columns) >= 3:  # ì—…ë¡œë“œ Cì—´ â†’ Sheet2 Fì—´ (ì£¼ë¬¸ìëª…)
                sheet2_row['Fì—´(ì£¼ë¬¸ìëª…)'] = str(row.iloc[2]) if pd.notna(row.iloc[2]) else ""
            
            # ì—…ë¡œë“œ Dì—´ â†’ Sheet2 Gì—´ (ìœ„íƒìëª…) + ì£¼ì†Œ 3ë²ˆì§¸ ë‹¨ì–´ ì¶”ê°€
            if len(sheet1_df.columns) >= 4:
                name = str(row.iloc[3]) if pd.notna(row.iloc[3]) else ""
                # ì£¼ì†Œì—ì„œ 3ë²ˆì§¸ ë‹¨ì–´ ì¶”ì¶œ (Kì—´ì´ ì£¼ì†Œ)
                address_third_word = ""
                if len(sheet1_df.columns) >= 11:  # Kì—´(ì£¼ì†Œ)ì´ ìˆìœ¼ë©´
                    address = str(row.iloc[10]) if pd.notna(row.iloc[10]) else ""
                    address_third_word = self.extract_third_word_from_address(address)
                
                if name and address_third_word:
                    sheet2_row['Gì—´(ìœ„íƒìëª…)'] = f"{name}({address_third_word})"
                else:
                    sheet2_row['Gì—´(ìœ„íƒìëª…)'] = name
            
            # ì—…ë¡œë“œ Eì—´ â†’ ë¸Œëœë“œ/ìƒí’ˆëª… ë¶„í•  (ìƒí’ˆëª…ì— í‚¤ì›Œë“œ ì œê±° ì ìš©)
            if len(sheet1_df.columns) >= 5:
                e_value = str(row.iloc[4]) if pd.notna(row.iloc[4]) else ""
                e_value = e_value.strip()  # ì•ë’¤ ê³µë°± ì œê±°
                
                if e_value:
                    # ê´„í˜¸ë¥¼ ì´ìš©í•œ ë¸Œëœë“œ ì¶”ì¶œ ì‹œë„ (ì˜ˆ: í´ë¼ë ˆì˜¤(ê¸°ë¦°) ìƒí’ˆëª…)
                    bracket_match = re.match(r'^([^)]+\)[^)]*?)\s+(.+)$', e_value)
                    if bracket_match:
                        # ê´„í˜¸ê°€ í¬í•¨ëœ ë¸Œëœë“œëª…ê³¼ ìƒí’ˆëª… ë¶„ë¦¬
                        brand_part = bracket_match.group(1).strip()
                        product_part = bracket_match.group(2).strip()
                        sheet2_row['Hì—´(ë¸Œëœë“œ)'] = brand_part
                        
                        # ìƒí’ˆëª…ì— í‚¤ì›Œë“œ ì œê±° ì ìš©
                        cleaned_product_name = self.normalize_product_name(product_part)
                        if len(cleaned_product_name) < 2:
                            # ì›ë³¸ì—ì„œ ê´„í˜¸ë§Œ ì œê±°
                            cleaned_product_name = product_part
                            for keyword in self.keyword_list:
                                if keyword:
                                    pattern = r'\(' + re.escape(keyword) + r'\)'
                                    cleaned_product_name = re.sub(pattern, '', cleaned_product_name, flags=re.IGNORECASE)
                            cleaned_product_name = re.sub(r'\s+', ' ', cleaned_product_name).strip()
                        
                        sheet2_row['Iì—´(ìƒí’ˆëª…)'] = cleaned_product_name
                        
                    elif ' ' in e_value:
                        # ì¼ë°˜ì ì¸ ë„ì–´ì“°ê¸° ë¶„í•  (ê³µë°± ì œê±° í›„)
                        parts = e_value.split(' ', 1)
                        if parts[0].strip():  # ì²« ë²ˆì§¸ ë¶€ë¶„ì´ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´
                            sheet2_row['Hì—´(ë¸Œëœë“œ)'] = parts[0].strip()
                            # ìƒí’ˆëª…ì— í‚¤ì›Œë“œ ì œê±° ì ìš©
                            raw_product_name = parts[1].strip() if len(parts) > 1 else ""
                            if raw_product_name:
                                cleaned_product_name = self.normalize_product_name(raw_product_name)
                                if len(cleaned_product_name) < 2:
                                    # ì›ë³¸ì—ì„œ ê´„í˜¸ë§Œ ì œê±°
                                    cleaned_product_name = raw_product_name
                                    for keyword in self.keyword_list:
                                        if keyword:
                                            pattern = r'\(' + re.escape(keyword) + r'\)'
                                            cleaned_product_name = re.sub(pattern, '', cleaned_product_name, flags=re.IGNORECASE)
                                    cleaned_product_name = re.sub(r'\s+', ' ', cleaned_product_name).strip()
                                
                                sheet2_row['Iì—´(ìƒí’ˆëª…)'] = cleaned_product_name
                            else:
                                sheet2_row['Iì—´(ìƒí’ˆëª…)'] = ""
                        else:
                            # ì²« ë²ˆì§¸ ë¶€ë¶„ì´ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ë¥¼ ìƒí’ˆëª…ìœ¼ë¡œ ì²˜ë¦¬
                            sheet2_row['Hì—´(ë¸Œëœë“œ)'] = ""
                            cleaned_product_name = self.normalize_product_name(e_value)
                            if len(cleaned_product_name) < 2:
                                cleaned_product_name = e_value
                            sheet2_row['Iì—´(ìƒí’ˆëª…)'] = cleaned_product_name
                    else:
                        # ë„ì–´ì“°ê¸°ê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ ë¸Œëœë“œë¡œ ì²˜ë¦¬
                        sheet2_row['Hì—´(ë¸Œëœë“œ)'] = e_value
                        sheet2_row['Iì—´(ìƒí’ˆëª…)'] = ""
                else:
                    sheet2_row['Hì—´(ë¸Œëœë“œ)'] = ""
                    sheet2_row['Iì—´(ìƒí’ˆëª…)'] = ""
            
            # ì—…ë¡œë“œ Fì—´ (ì˜µì…˜) â†’ ìƒ‰ìƒ/ì‚¬ì´ì¦ˆ ì¶”ì¶œ
            if len(sheet1_df.columns) >= 6:
                f_value = str(row.iloc[5]) if pd.notna(row.iloc[5]) else ""
                sheet2_row['Jì—´(ìƒ‰ìƒ)'], sheet2_row['Kì—´(ì‚¬ì´ì¦ˆ)'] = self.parse_options(f_value)
            
            if len(sheet1_df.columns) >= 7:  # ì—…ë¡œë“œ Gì—´ â†’ Sheet2 Lì—´ (ìˆ˜ëŸ‰)
                try:
                    sheet2_row['Lì—´(ìˆ˜ëŸ‰)'] = int(row.iloc[6]) if pd.notna(row.iloc[6]) else 1
                except:
                    sheet2_row['Lì—´(ìˆ˜ëŸ‰)'] = 1
            
            # ì—…ë¡œë“œ Hì—´ â†’ Sheet2 Mì—´ (ì˜µì…˜ê°€) - ìƒˆë¡œ ì¶”ê°€
            if len(sheet1_df.columns) >= 8:
                sheet2_row['Mì—´(ì˜µì…˜ê°€)'] = str(row.iloc[7]) if pd.notna(row.iloc[7]) else ""
            
            # ì—…ë¡œë“œ Iì—´ â†’ Sheet2 Rì—´ (ì´ë¦„) + ì£¼ì†Œ 3ë²ˆì§¸ ë‹¨ì–´ ì¶”ê°€
            if len(sheet1_df.columns) >= 9:
                name = str(row.iloc[8]) if pd.notna(row.iloc[8]) else ""
                # ì£¼ì†Œì—ì„œ 3ë²ˆì§¸ ë‹¨ì–´ ì¶”ì¶œ (Kì—´ì´ ì£¼ì†Œ)
                address_third_word = ""
                if len(sheet1_df.columns) >= 11:  # Kì—´(ì£¼ì†Œ)ì´ ìˆìœ¼ë©´
                    address = str(row.iloc[10]) if pd.notna(row.iloc[10]) else ""
                    address_third_word = self.extract_third_word_from_address(address)
                
                if name and address_third_word:
                    sheet2_row['Rì—´(ì´ë¦„)'] = f"{name}({address_third_word})"
                else:
                    sheet2_row['Rì—´(ì´ë¦„)'] = name
            
            if len(sheet1_df.columns) >= 10:  # ì—…ë¡œë“œ Jì—´ â†’ Sheet2 Sì—´ (ì „í™”ë²ˆí˜¸)
                sheet2_row['Sì—´(ì „í™”ë²ˆí˜¸)'] = str(row.iloc[9]) if pd.notna(row.iloc[9]) else ""
            
            if len(sheet1_df.columns) >= 11:  # ì—…ë¡œë“œ Kì—´ â†’ Sheet2 Tì—´ (ì£¼ì†Œ)
                sheet2_row['Tì—´(ì£¼ì†Œ)'] = str(row.iloc[10]) if pd.notna(row.iloc[10]) else ""
            
            if len(sheet1_df.columns) >= 12:  # ì—…ë¡œë“œ Lì—´ â†’ Sheet2 Vì—´ (ë°°ì†¡ë©”ì„¸ì§€)
                sheet2_row['Vì—´(ë°°ì†¡ë©”ì„¸ì§€)'] = str(row.iloc[11]) if pd.notna(row.iloc[11]) else ""
            
            # ë§¤ì¹­ ê²°ê³¼ëŠ” ë‚˜ì¤‘ì— ì±„ì›€
            sheet2_row['Nì—´(ì¤‘ë„ë§¤ëª…)'] = ""
            sheet2_row['Oì—´(ë„ë§¤ê°€ê²©)'] = 0
            sheet2_row['Wì—´(ê¸ˆì•¡)'] = 0
            
            # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ì„±ëŠ¥ ìµœì í™”)
            sheet2_rows.append(sheet2_row)

        # ëª¨ë“  í–‰ì„ í•œ ë²ˆì— DataFrameìœ¼ë¡œ ìƒì„± (ì„±ëŠ¥ ìµœì í™”)
        sheet2_df = pd.DataFrame(sheet2_rows, columns=sheet2_columns)
        
        total_elapsed = time.time() - start_time
        logger.info(f"Sheet2 ë³€í™˜ ì™„ë£Œ: {len(sheet2_df):,}ê°œ í–‰ - ì†Œìš”ì‹œê°„: {total_elapsed:.1f}ì´ˆ")
        return sheet2_df

    def extract_size(self, text: str) -> str:
        """ì‚¬ì´ì¦ˆ{...} íŒ¨í„´ì—ì„œ ì‚¬ì´ì¦ˆ ì¶”ì¶œ (ë¸Œëœë“œë§¤ì¹­ì‹œíŠ¸ìš©)"""
        if pd.isna(text):
            return ""

        # ë¸Œëœë“œë§¤ì¹­ì‹œíŠ¸ì˜ ì‹¤ì œ íŒ¨í„´: ìƒ‰ìƒ{...}//ì‚¬ì´ì¦ˆ{...}
        # ë˜ëŠ” ê¸°ì¡´ íŒ¨í„´: ì‚¬ì´ì¦ˆ{...}
        size_match = re.search(r"ì‚¬ì´ì¦ˆ\{([^}]*)\}", str(text))
        if size_match:
            size_content = size_match.group(1).strip().lower()
            # | ë˜ëŠ” \ ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰í•˜ê¸° ì‰½ê²Œ ë§Œë“¦
            size_content = size_content.replace('|', ' ').replace('\\', ' ')
            return size_content
        
        return ""

    def extract_color(self, text: str) -> str:
        """ìƒ‰ìƒ{...} íŒ¨í„´ì—ì„œ ìƒ‰ìƒ ì¶”ì¶œ (ë¸Œëœë“œë§¤ì¹­ì‹œíŠ¸ìš©)"""
        if pd.isna(text):
            return ""

        # ë¸Œëœë“œë§¤ì¹­ì‹œíŠ¸ì˜ íŒ¨í„´: ìƒ‰ìƒ{...}//ì‚¬ì´ì¦ˆ{...}
        color_match = re.search(r"ìƒ‰ìƒ\{([^}]*)\}", str(text))
        if color_match:
            color_content = color_match.group(1).strip().lower()
            # | ë˜ëŠ” \ ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰í•˜ê¸° ì‰½ê²Œ ë§Œë“¦
            color_content = color_content.replace('|', ' ').replace('\\', ' ')
            return color_content
        
        return ""

    def match_row(self, brand: str, product: str, size: str, color: str = "") -> Tuple[str, str, str, bool]:
        """ë¸Œëœë“œ, ìƒí’ˆëª…, ì‚¬ì´ì¦ˆ, ìƒ‰ìƒìœ¼ë¡œ ë§¤ì¹­í•˜ì—¬ ê³µê¸‰ê°€, ì¤‘ë„ë§¤, ë¸Œëœë“œ+ìƒí’ˆëª…, ë§¤ì¹­ì„±ê³µì—¬ë¶€ ë°˜í™˜"""
        import time
        start_time = time.time()
        
        # ë¹ ë¥¸ ì‹¤íŒ¨: ë¹ˆ ê°’ ì²´í¬
        brand = str(brand).strip()
        product = str(product).strip()
        
        if not brand or not product:
            return "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False
        
        size = str(size).strip().lower()
        color = str(color).strip().lower()
        
        # ì‚¬ì´ì¦ˆ í˜•ì‹ ì •ê·œí™”
        size = self.normalize_size_format(size)

        # ìƒí’ˆëª… ì •ê·œí™” (í‚¤ì›Œë“œ ì œê±°)
        normalized_product = self.normalize_product_name(product)

        logger.debug(f"ë§¤ì¹­ ì‹œë„: ë¸Œëœë“œ='{brand}', ìƒí’ˆëª…='{product[:30]}' (ì •ê·œí™”: '{normalized_product[:30]}'), ì‚¬ì´ì¦ˆ='{size}', ìƒ‰ìƒ='{color}'")

        if self.brand_data is None or self.brand_data.empty:
            logger.warning("ë¸Œëœë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False

        # âš¡ ì†ë„ ìµœì í™”: ë¸Œëœë“œ ì¸ë±ìŠ¤ í™œìš© (row ë°ì´í„° ì§ì ‘ ì‚¬ìš©)
        brand_lower = brand.lower()
        candidate_rows = self.brand_index.get(brand_lower, [])
        
        if not candidate_rows:
            logger.debug(f"ë¸Œëœë“œ '{brand}' ì¸ë±ìŠ¤ì— ì—†ìŒ")
            return "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False
        
        logger.debug(f"âš¡ ë¸Œëœë“œ '{brand}' ì¸ë±ìŠ¤ ê²€ìƒ‰ ê²°ê³¼: {len(candidate_rows)}ê°œ ìƒí’ˆ")

        # âš¡ ìœ ì‚¬ë„ ë§¤ì¹­: 2ë‹¨ê³„ ì ‘ê·¼
        # 1ë‹¨ê³„: ìƒí’ˆëª… ìœ ì‚¬ë„ë§Œ ë¹ ë¥´ê²Œ ê³„ì‚°í•˜ì—¬ í›„ë³´ ì„ ì •
        product_candidates = []
        processed_count = 0
        
        # âš¡ row ë°ì´í„°ë¥¼ ì§ì ‘ ì‚¬ìš© (iloc ì™„ì „ ì œê±°!)
        for row_dict in candidate_rows:
            processed_count += 1
            
            # íƒ€ì„ì•„ì›ƒ ì²´í¬ (1ë‹¨ê³„ëŠ” ë¹ ë¥´ë¯€ë¡œ 1ì´ˆë¡œ ë‹¨ì¶•)
            if time.time() - start_time > 1:
                logger.warning(f"â° 1ë‹¨ê³„ íƒ€ì„ì•„ì›ƒ (1ì´ˆ): ë¸Œëœë“œ='{brand}' ({processed_count}ê°œ ì²˜ë¦¬ë¨)")
                break
            
            # 1ë‹¨ê³„: ìƒí’ˆëª… ìœ ì‚¬ë„ë§Œ ë¹ ë¥´ê²Œ ê³„ì‚°
            row_product_raw = str(row_dict.get('ìƒí’ˆëª…', '')).strip()
            row_product = self.normalize_product_name(row_product_raw)
            product_similarity = self.calculate_similarity(normalized_product, row_product)
            
            # ìƒí’ˆëª… ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ìŠ¤í‚µ (85%ë¡œ ê°•í™”í•˜ì—¬ ì •í™•ë„ í–¥ìƒ)
            # ëª©ì : ë‹¤ë¥¸ ë¯¸ë‹ˆë¡œë¸Œ ìƒí’ˆê³¼ì˜ ì˜¤ë§¤ì¹­ ë°©ì§€
            if product_similarity < 85:
                continue
            
            # ê¸¸ì´ ë¹„ìœ¨ ì²´í¬
            min_len = min(len(normalized_product), len(row_product))
            max_len = max(len(normalized_product), len(row_product))
            length_ratio = min_len / max_len if max_len > 0 else 0
            
            if length_ratio < 0.7:
                continue
            
            # í›„ë³´ë¡œ ì¶”ê°€ (ìƒí’ˆëª… ìœ ì‚¬ë„ì™€ í•¨ê»˜ ì €ì¥)
            product_candidates.append({
                'row_dict': row_dict,
                'product_similarity': product_similarity,
                'row_product': row_product
            })
        
        # í›„ë³´ê°€ ì—†ìœ¼ë©´ ì‹¤íŒ¨
        if not product_candidates:
            logger.debug(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨: ìƒí’ˆëª… ìœ ì‚¬ë„ 70% ì´ìƒ í›„ë³´ ì—†ìŒ")
            return "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False
        
        # 2ë‹¨ê³„: ìƒí’ˆëª… ìœ ì‚¬ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ í›„ ìƒìœ„ 5ê°œë§Œ ìƒì„¸ í‰ê°€
        product_candidates.sort(key=lambda x: x['product_similarity'], reverse=True)
        top_candidates = product_candidates[:5]  # ìƒìœ„ 5ê°œë§Œ
        
        logger.debug(f"âš¡ 1ë‹¨ê³„ ì™„ë£Œ: {len(product_candidates)}ê°œ í›„ë³´ ì¤‘ ìƒìœ„ {len(top_candidates)}ê°œ ìƒì„¸ í‰ê°€")
        
        # 2ë‹¨ê³„: ìƒìœ„ í›„ë³´ë“¤ë§Œ ìƒ‰ìƒ/ì‚¬ì´ì¦ˆ ìœ ì‚¬ë„ ê³„ì‚°
        best_match = None
        best_similarity = 0.0
        
        for candidate in top_candidates:
            row_dict = candidate['row_dict']
            product_similarity = candidate['product_similarity']
            
            # ìƒ‰ìƒ ìœ ì‚¬ë„ ê³„ì‚°
            color_similarity = 100.0
            if color:
                row_color_pattern = self.extract_color(str(row_dict.get('ì˜µì…˜ì…ë ¥', '')))
                if row_color_pattern:
                    color_similarity = self.calculate_similarity(color, row_color_pattern)
                else:
                    color_similarity = 0.0
            
            # ì‚¬ì´ì¦ˆ ìœ ì‚¬ë„ ê³„ì‚° (ì •í™• ë§¤ì¹­ ê°•í™”)
            size_similarity = 100.0
            if size:
                row_size_pattern = self.extract_size(str(row_dict.get('ì˜µì…˜ì…ë ¥', '')))
                if row_size_pattern:
                    size_similarity = self.check_size_match(size, row_size_pattern)
                else:
                    size_similarity = 0.0
                
                # ğŸš¨ ì‚¬ì´ì¦ˆ ì„ê³„ê°’ ì²´í¬ (50% ë¯¸ë§Œ ì°¨ë‹¨)
                # ëª©ì : ì£¼ë‹ˆì–´ ì‚¬ì´ì¦ˆ ì˜¤ë§¤ì¹­ ë°©ì§€ (Sâ†’JS, Mâ†’JM ë“±)
                if size_similarity < 50:
                    logger.debug(f"âŒ ì‚¬ì´ì¦ˆ ìœ ì‚¬ë„ ë„ˆë¬´ ë‚®ìŒ: {size_similarity:.1f}% < 50% (ì—…ë¡œë“œ: {size}, ë¸Œëœë“œ: {row_size_pattern})")
                    continue  # ì´ í›„ë³´ëŠ” í‰ê°€ì—ì„œ ì œì™¸
            
            # ê°€ê²© ìœ ì‚¬ë„ ê³„ì‚° (ì˜¤ë§¤ì¹­ ë°©ì§€)
            # ì°¸ê³ : ì—…ë¡œë“œ íŒŒì¼ì—ëŠ” ê°€ê²©ì´ ì—†ìœ¼ë¯€ë¡œ, ë¸Œëœë“œ ì‹œíŠ¸ ë‚´ ìœ ì‚¬ ìƒí’ˆ ê°„ ê°€ê²© ë¹„êµ
            # í˜„ì¬ëŠ” ê°€ê²© ì •ë³´ë¥¼ í™œìš©í•˜ì§€ ì•Šì§€ë§Œ, í–¥í›„ í™•ì¥ ê°€ëŠ¥
            price_similarity = 50.0  # ì¤‘ë¦½ (ê°€ê²© ì •ë³´ ì—†ìŒ)
            
            # ì¢…í•© ìœ ì‚¬ë„ ê³„ì‚° (ê°€ê²© ê°€ì¤‘ì¹˜ 5% ì¶”ê°€)
            total_similarity = (
                product_similarity * 0.45 +  # 45% (ê¸°ì¡´ 50%ì—ì„œ ì¡°ì •)
                size_similarity * 0.30 +      # 30%
                color_similarity * 0.20 +     # 20%
                price_similarity * 0.05       # 5% (í–¥í›„ í™•ì¥ ê°€ëŠ¥)
            )
            
            logger.debug(f"í›„ë³´ í‰ê°€: {row_dict.get('ìƒí’ˆëª…', '')[:20]}... (ìƒí’ˆ={product_similarity:.1f}%, ì‚¬ì´ì¦ˆ={size_similarity:.1f}%, ìƒ‰ìƒ={color_similarity:.1f}%, ì¢…í•©={total_similarity:.1f}%)")
            
            # ì¢…í•© ìœ ì‚¬ë„ê°€ 60% ë¯¸ë§Œì´ë©´ ìŠ¤í‚µ
            if total_similarity < 60:
                continue
            
            # í˜„ì¬ í›„ë³´ ì •ë³´
            ê³µê¸‰ê°€ = row_dict.get('ê³µê¸‰ê°€', 0)
            ì¤‘ë„ë§¤ = row_dict.get('ì¤‘ë„ë§¤', '')
            ë¸Œëœë“œìƒí’ˆëª… = f"{row_dict.get('ë¸Œëœë“œ', '')} {row_dict.get('ìƒí’ˆëª…', '')}"
            
            # 92% ì´ìƒì´ë©´ ì¦‰ì‹œ ë¦¬í„´ (ê±°ì˜ ì™„ë²½í•œ ë§¤ì¹­ - ì˜¤ë§¤ì¹­ ë°©ì§€)
            if total_similarity >= 92:
                logger.debug(f"âœ… ë†’ì€ ìœ ì‚¬ë„ ë§¤ì¹­ ë°œê²¬ ({total_similarity:.1f}%): {ë¸Œëœë“œìƒí’ˆëª…} - ì¦‰ì‹œ ë¦¬í„´!")
                return ê³µê¸‰ê°€, ì¤‘ë„ë§¤, ë¸Œëœë“œìƒí’ˆëª…, True
            
            # ìµœê³  ìœ ì‚¬ë„ ì—…ë°ì´íŠ¸
            if total_similarity > best_similarity:
                best_similarity = total_similarity
                best_match = {
                    'similarity': total_similarity,
                    'ê³µê¸‰ê°€': ê³µê¸‰ê°€,
                    'ì¤‘ë„ë§¤': ì¤‘ë„ë§¤,
                    'ë¸Œëœë“œìƒí’ˆëª…': ë¸Œëœë“œìƒí’ˆëª…,
                    'product_sim': product_similarity,
                    'size_sim': size_similarity,
                    'color_sim': color_similarity
                }

        # ìµœê³  ìœ ì‚¬ë„ ë§¤ì¹­ ê²°ê³¼ ë°˜í™˜
        if best_match and best_similarity >= 60:
            logger.debug(f"âœ… ìµœì¢… ë§¤ì¹­ ì„ íƒ: {best_match['ë¸Œëœë“œìƒí’ˆëª…']} (ìœ ì‚¬ë„: {best_similarity:.1f}%)")
            logger.debug(f"   ìƒì„¸: ìƒí’ˆ={best_match['product_sim']:.1f}%, ì‚¬ì´ì¦ˆ={best_match['size_sim']:.1f}%, ìƒ‰ìƒ={best_match['color_sim']:.1f}%")
            return best_match['ê³µê¸‰ê°€'], best_match['ì¤‘ë„ë§¤'], best_match['ë¸Œëœë“œìƒí’ˆëª…'], True

        logger.debug(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨ (ìµœê³  ìœ ì‚¬ë„: {best_similarity:.1f}% < 60%)")
        return "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False

    def process_matching(self, sheet2_df: pd.DataFrame) -> Tuple[pd.DataFrame, List[Dict]]:
        """Sheet2 ë°ì´í„°ì— ëŒ€í•´ ë§¤ì¹­ ìˆ˜í–‰í•˜ê³  ë§¤ì¹­ ì‹¤íŒ¨í•œ ìƒí’ˆë“¤ ë°˜í™˜"""
        import time
        logger.info("ë§¤ì¹­ ì²˜ë¦¬ ì‹œì‘")

        if sheet2_df.empty:
            logger.warning("ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return sheet2_df, []

        success_count = 0
        total_count = len(sheet2_df)
        failed_products = []  # ë§¤ì¹­ ì‹¤íŒ¨í•œ ìƒí’ˆë“¤
        start_time = time.time()
        
        print(f"\nì´ {total_count:,}ê°œ í–‰ ì²˜ë¦¬ ì‹œì‘...", flush=True)
        logger.info(f"ì´ {total_count:,}ê°œ í–‰ ì²˜ë¦¬ ì‹œì‘")

        # âš¡ ì„±ëŠ¥ ê°œì„ : ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ëª¨ì•˜ë‹¤ê°€ í•œ ë²ˆì— í• ë‹¹ (at ë°˜ë³µ ì‚¬ìš© ë°©ì§€)
        results = {
            'Nì—´(ì¤‘ë„ë§¤ëª…)': [''] * len(sheet2_df),
            'Oì—´(ë„ë§¤ê°€ê²©)': [0] * len(sheet2_df),
            'Wì—´(ê¸ˆì•¡)': [0] * len(sheet2_df)
        }
        
        # âš¡ ìµœê³  ì†ë„: to_dict('records') ì‚¬ìš© (ê°€ì¥ ë¹ ë¦„!)
        rows_dict = sheet2_df.to_dict('records')
        indices = sheet2_df.index.tolist()
        
        for current_index, (row_dict, idx) in enumerate(zip(rows_dict, indices)):
            # ì§„í–‰ë¥  í‘œì‹œ (ë§¤ í•­ëª©ë§ˆë‹¤ - ì¦‰ì‹œ ì¶œë ¥)
            elapsed_time = time.time() - start_time
            progress = ((current_index + 1) / total_count) * 100
            
            # ë§¤ í•­ëª©ë§ˆë‹¤ ì§§ê²Œ ì¶œë ¥
            print(f"\rì§„í–‰: {current_index + 1}/{total_count} ({progress:.0f}%)", end='', flush=True)
            
            # 10ê°œë§ˆë‹¤ ìƒì„¸ ì¶œë ¥
            if (current_index + 1) % 10 == 0:
                avg_time = elapsed_time / (current_index + 1)
                eta = avg_time * (total_count - current_index - 1)
                print(f"\rì§„í–‰ë¥ : {current_index + 1:,}/{total_count:,} ({progress:.1f}%) - ê²½ê³¼: {elapsed_time:.1f}ì´ˆ, ì˜ˆìƒ: {eta:.1f}ì´ˆ", flush=True)
                
                # íƒ€ì„ì•„ì›ƒ ì²´í¬ (10ë¶„ìœ¼ë¡œ ë‹¨ì¶•)
                if elapsed_time > 600:  # 10ë¶„
                    logger.error("ë§¤ì¹­ ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ (10ë¶„ ì´ˆê³¼) - ì²˜ë¦¬ ì¤‘ë‹¨")
                    break
            
            # ë¸Œëœë“œ, ìƒí’ˆëª…, ì‚¬ì´ì¦ˆ ì¶”ì¶œ
            brand = str(row_dict.get('Hì—´(ë¸Œëœë“œ)', '')).strip()
            product = str(row_dict.get('Iì—´(ìƒí’ˆëª…)', '')).strip()
            size = str(row_dict.get('Kì—´(ì‚¬ì´ì¦ˆ)', '')).strip()
            color = str(row_dict.get('Jì—´(ìƒ‰ìƒ)', '')).strip()
            quantity = row_dict.get('Lì—´(ìˆ˜ëŸ‰)', 1)

            # ë¹ˆ ê°’ ì²´í¬
            if not brand or not product:
                results['Nì—´(ì¤‘ë„ë§¤ëª…)'][current_index] = ""
                results['Oì—´(ë„ë§¤ê°€ê²©)'][current_index] = 0
                results['Wì—´(ê¸ˆì•¡)'][current_index] = 0
                continue

            # ë§¤ì¹­ ìˆ˜í–‰ (íƒ€ì„ì•„ì›ƒ ì ìš©)
            try:
                row_start_time = time.time()
                ê³µê¸‰ê°€, ì¤‘ë„ë§¤, ë¸Œëœë“œìƒí’ˆëª…, success = self.match_row(brand, product, size, color)
                row_elapsed = time.time() - row_start_time
                
                # ë‹¨ì¼ í–‰ ì²˜ë¦¬ê°€ 3ì´ˆë¥¼ ì´ˆê³¼í•˜ë©´ ê²½ê³ 
                if row_elapsed > 3:
                    print(f"âš ï¸  í–‰ {current_index} ëŠë¦¼: {row_elapsed:.1f}ì´ˆ", flush=True)
                
                # ë‹¨ì¼ í–‰ ì²˜ë¦¬ê°€ 10ì´ˆë¥¼ ì´ˆê³¼í•˜ë©´ ê°•ì œ ì¤‘ë‹¨
                if row_elapsed > 10:
                    print(f"âŒ í–‰ {current_index} ì‹œê°„ ì´ˆê³¼ (10ì´ˆ)", flush=True)
                    ê³µê¸‰ê°€, ì¤‘ë„ë§¤, ë¸Œëœë“œìƒí’ˆëª…, success = "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False
                
            except Exception as e:
                logger.error(f"í–‰ {current_index} ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜: {e} (ë¸Œëœë“œ: {brand}, ìƒí’ˆ: {product})")
                ê³µê¸‰ê°€, ì¤‘ë„ë§¤, ë¸Œëœë“œìƒí’ˆëª…, success = "ë§¤ì¹­ ì‹¤íŒ¨", "", "", False

            # ê²°ê³¼ ì €ì¥ (ë¦¬ìŠ¤íŠ¸ì— - ë¹ ë¦„!)
            if success and ê³µê¸‰ê°€ != "ë§¤ì¹­ ì‹¤íŒ¨":
                results['Nì—´(ì¤‘ë„ë§¤ëª…)'][current_index] = ì¤‘ë„ë§¤
                results['Oì—´(ë„ë§¤ê°€ê²©)'][current_index] = ê³µê¸‰ê°€
                # Wì—´ ê¸ˆì•¡ ê³„ì‚°: ë„ë§¤ê°€ê²© Ã— ìˆ˜ëŸ‰
                try:
                    total_amount = float(ê³µê¸‰ê°€) * int(quantity)
                    results['Wì—´(ê¸ˆì•¡)'][current_index] = total_amount
                except:
                    results['Wì—´(ê¸ˆì•¡)'][current_index] = 0
                success_count += 1
            else:
                # ë§¤ì¹­ ì‹¤íŒ¨í•œ ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ (í•„ìˆ˜ ì •ë³´ë§Œ)
                failed_product = {
                    'ë¸Œëœë“œ': brand,
                    'ìƒí’ˆëª…': product,
                    'ìƒ‰ìƒ': color,
                    'ì‚¬ì´ì¦ˆ': size,
                    'ìˆ˜ëŸ‰': quantity,
                    'í–‰ë²ˆí˜¸': idx
                }
                
                # âš¡ ì„±ëŠ¥ ê°œì„ : row.items() ì œê±° (ë§¤ìš° ëŠë¦¼!)
                # ì›ë³¸ ë°ì´í„°ëŠ” ë‚˜ì¤‘ì— sheet2_dfì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
                
                failed_products.append(failed_product)
                
                results['Nì—´(ì¤‘ë„ë§¤ëª…)'][current_index] = ""
                results['Oì—´(ë„ë§¤ê°€ê²©)'][current_index] = 0
                results['Wì—´(ê¸ˆì•¡)'][current_index] = 0

        # âš¡ ì„±ëŠ¥ ê°œì„ : ë£¨í”„ ì™„ë£Œ í›„ í•œ ë²ˆì— í• ë‹¹ (ë§¤ìš° ë¹ ë¦„!)
        print("\nê²°ê³¼ ì €ì¥ ì¤‘...", flush=True)
        sheet2_df['Nì—´(ì¤‘ë„ë§¤ëª…)'] = results['Nì—´(ì¤‘ë„ë§¤ëª…)']
        sheet2_df['Oì—´(ë„ë§¤ê°€ê²©)'] = results['Oì—´(ë„ë§¤ê°€ê²©)']
        sheet2_df['Wì—´(ê¸ˆì•¡)'] = results['Wì—´(ê¸ˆì•¡)']
        
        total_elapsed = time.time() - start_time
        success_rate = (success_count / total_count * 100) if total_count > 0 else 0
        msg = f"ë§¤ì¹­ ì™„ë£Œ: {success_count:,}/{total_count:,} ({success_rate:.1f}%) - ì´ ì†Œìš”ì‹œê°„: {total_elapsed:.1f}ì´ˆ"
        print(msg, flush=True)
        logger.info(msg)
        logger.info(f"ë§¤ì¹­ ì‹¤íŒ¨: {len(failed_products):,}ê°œ ìƒí’ˆ")

        return sheet2_df, failed_products

    def process_matching_with_similarity(self, sheet2_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """ë§¤ì¹­ ìˆ˜í–‰ í›„ ì‹¤íŒ¨í•œ ìƒí’ˆë“¤ì— ëŒ€í•´ ìœ ì‚¬ë„ ë§¤ì¹­ ì¶”ê°€ ìˆ˜í–‰"""
        logger.info("ì •í™• ë§¤ì¹­ + ìœ ì‚¬ë„ ë§¤ì¹­ ì²˜ë¦¬ ì‹œì‘")
        
        # 1ë‹¨ê³„: ì •í™• ë§¤ì¹­
        matched_df, failed_products = self.process_matching(sheet2_df)
        
        # 2ë‹¨ê³„: ë§¤ì¹­ ì‹¤íŒ¨í•œ ìƒí’ˆë“¤ì— ëŒ€í•´ ìœ ì‚¬ë„ ë§¤ì¹­
        similarity_results_df = pd.DataFrame()
        if failed_products:
            logger.info(f"ë§¤ì¹­ ì‹¤íŒ¨í•œ {len(failed_products)}ê°œ ìƒí’ˆì— ëŒ€í•´ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œì‘")
            similarity_results_df = self.find_similar_products_for_failed_matches(failed_products)
        
        return matched_df, similarity_results_df

    def save_to_excel(self, sheet2_df: pd.DataFrame, filename: str = "ë¸Œëœë“œë§¤ì¹­ê²°ê³¼.xlsx"):
        """Sheet2 í˜•ì‹ìœ¼ë¡œ ì—‘ì…€ íŒŒì¼ ì €ì¥"""
        try:
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                # Sheet2 íƒ­ì— ì €ì¥
                sheet2_df.to_excel(writer, sheet_name='Sheet2', index=False)

                # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
                worksheet = writer.sheets['Sheet2']
                for i, column in enumerate(sheet2_df.columns, 1):
                    if i <= 26:
                        column_letter = chr(64 + i)
                    else:
                        column_letter = f"A{chr(64 + i - 26)}"
                    worksheet.column_dimensions[column_letter].width = 15

            logger.info(f"ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
            return filename

        except Exception as e:
            logger.error(f"ì—‘ì…€ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise e

    def save_similarity_results_to_excel(self, similarity_df: pd.DataFrame, filename: str = "ìœ ì‚¬ë„ë§¤ì¹­ê²°ê³¼.xlsx"):
        """ìœ ì‚¬ë„ ë§¤ì¹­ ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                # ìœ ì‚¬ë„ ë§¤ì¹­ ê²°ê³¼ ì €ì¥
                similarity_df.to_excel(writer, sheet_name='ìœ ì‚¬ë„ë§¤ì¹­ê²°ê³¼', index=False)

                # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
                worksheet = writer.sheets['ìœ ì‚¬ë„ë§¤ì¹­ê²°ê³¼']
                for i, column in enumerate(similarity_df.columns, 1):
                    column_letter = self._get_column_letter(i)
                    
                    # ì»¬ëŸ¼ëª…ì— ë”°ë¥¸ ë„ˆë¹„ ì¡°ì •
                    if 'ìƒí’ˆëª…' in column:
                        worksheet.column_dimensions[column_letter].width = 30
                    elif 'ìœ ì‚¬ë„' in column:
                        worksheet.column_dimensions[column_letter].width = 12
                    elif 'ë¸Œëœë“œ' in column:
                        worksheet.column_dimensions[column_letter].width = 15
                    elif 'ìƒ‰ìƒ' in column or 'ì‚¬ì´ì¦ˆ' in column:
                        worksheet.column_dimensions[column_letter].width = 15
                    elif 'ì¤‘ë„ë§¤' in column or 'ê³µê¸‰ê°€' in column:
                        worksheet.column_dimensions[column_letter].width = 12
                    else:
                        worksheet.column_dimensions[column_letter].width = 15

                # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
                from openpyxl.styles import Font, PatternFill, Alignment
                header_font = Font(bold=True, color="FFFFFF")
                header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
                
                for cell in worksheet[1]:
                    cell.font = header_font
                    cell.fill = header_fill
                    cell.alignment = Alignment(horizontal="center")

                # ìœ ì‚¬ë„ ì»¬ëŸ¼ì— ì¡°ê±´ë¶€ ì„œì‹ ì ìš©
                for col_idx, column in enumerate(similarity_df.columns, 1):
                    if 'ìœ ì‚¬ë„' in column:
                        column_letter = self._get_column_letter(col_idx)
                        for row_idx in range(2, len(similarity_df) + 2):
                            cell = worksheet[f"{column_letter}{row_idx}"]
                            try:
                                value = float(cell.value)
                                if value >= 0.8:
                                    cell.fill = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
                                elif value >= 0.6:
                                    cell.fill = PatternFill(start_color="FFEB9C", end_color="FFEB9C", fill_type="solid")
                                elif value >= 0.3:
                                    cell.fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
                            except:
                                pass

            logger.info(f"ìœ ì‚¬ë„ ë§¤ì¹­ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
            return filename

        except Exception as e:
            logger.error(f"ìœ ì‚¬ë„ ë§¤ì¹­ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise e

    def _get_column_letter(self, col_idx: int) -> str:
        """ì»¬ëŸ¼ ì¸ë±ìŠ¤ë¥¼ ì—‘ì…€ ì»¬ëŸ¼ ë¬¸ìë¡œ ë³€í™˜"""
        result = ""
        while col_idx > 0:
            col_idx -= 1
            result = chr(col_idx % 26 + ord('A')) + result
            col_idx //= 26
        return result 